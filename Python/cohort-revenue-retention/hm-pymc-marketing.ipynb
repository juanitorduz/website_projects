{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233255f8",
   "metadata": {},
   "source": [
    "# Cohort-Based CLV Forecasting with PyMC-Marketing\n",
    "\n",
    "This notebook implements a **cohort-based approach** to Customer Lifetime Value (CLV)\n",
    "forecasting using PyMC-Marketing's BG/NBD and Gamma-Gamma models.\n",
    "\n",
    "## Approach\n",
    "\n",
    "Instead of fitting a single model to all ~1.3M customers, we fit separate models\n",
    "per monthly cohort. This addresses two key challenges:\n",
    "\n",
    "1. **Dataset Size**: Each cohort has a manageable number of customers\n",
    "2. **Seasonality**: Different cohorts capture seasonal acquisition patterns implicitly\n",
    "\n",
    "## Models\n",
    "\n",
    "- **BG/NBD (Beta-Geometric/NBD)**: Models customer purchase frequency and dropout\n",
    "- **Gamma-Gamma**: Models monetary value of transactions\n",
    "\n",
    "## Data Source\n",
    "\n",
    "[H&M Personalized Fashion Recommendations](https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4268a3",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup and Configuration\n",
    "\n",
    "**Global Parameters:**\n",
    "\n",
    "- `MAX_COHORT_SIZE`: Controls subsampling for faster testing/debugging.\n",
    "  - Set to an integer (e.g., 10000) to subsample large cohorts\n",
    "  - Set to `None` for production runs with full data\n",
    "\n",
    "**Usage:**\n",
    "```python\n",
    "MAX_COHORT_SIZE = 10000  # Fast testing (~10 min total)\n",
    "MAX_COHORT_SIZE = None   # Full dataset (production run)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d30d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "from typing import Any\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import xarray as xr\n",
    "from pymc_extras.prior import Prior\n",
    "from pymc_marketing.clv import BetaGeoModel, GammaGammaModel\n",
    "\n",
    "# Plotting configuration\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9dfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GLOBAL CONFIGURATION PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "# MAX_COHORT_SIZE: Maximum number of customers per cohort for model fitting.\n",
    "# - Set to an integer (e.g., 10000) for faster testing/debugging\n",
    "# - Set to None to use all customers (production run)\n",
    "MAX_COHORT_SIZE: int | None = None  # Change to None for full dataset\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED: int = sum(map(ord, \"hm_clv_cohort_based\"))\n",
    "RNG: np.random.Generator = np.random.default_rng(seed=SEED)\n",
    "\n",
    "# Model configurations with informative priors for numerical stability\n",
    "BG_NBD_MODEL_CONFIG: dict[str, Prior] = {\n",
    "    \"a\": Prior(\"HalfNormal\", sigma=10),\n",
    "    \"b\": Prior(\"HalfNormal\", sigma=10),\n",
    "    \"alpha\": Prior(\"HalfNormal\", sigma=10),\n",
    "    \"r\": Prior(\"HalfNormal\", sigma=10),\n",
    "}\n",
    "\n",
    "GAMMA_GAMMA_MODEL_CONFIG: dict[str, Prior] = {\n",
    "    \"p\": Prior(\"HalfNormal\", sigma=10),\n",
    "    \"q\": Prior(\"HalfNormal\", sigma=10),\n",
    "    \"v\": Prior(\"HalfNormal\", sigma=100),\n",
    "}\n",
    "\n",
    "print(f\"MAX_COHORT_SIZE: {MAX_COHORT_SIZE}\")\n",
    "print(f\"SEED: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62f7f97",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading and Exploration\n",
    "\n",
    "We load the H&M transactions dataset containing:\n",
    "- `t_dat`: Transaction date\n",
    "- `customer_id`: Unique customer identifier\n",
    "- `price`: Transaction amount\n",
    "\n",
    "The dataset spans from September 2018 to September 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw transaction data\n",
    "# Source: https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data\n",
    "raw_df = pl.read_csv(\n",
    "    \"../../data/transactions_train.csv\",\n",
    "    columns=[\"t_dat\", \"customer_id\", \"price\"],\n",
    "    try_parse_dates=True,\n",
    ")\n",
    "\n",
    "print(f\"Raw data shape: {raw_df.shape}\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5edde81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(f\"Date range: {raw_df['t_dat'].min()} to {raw_df['t_dat'].max()}\")\n",
    "print(f\"Number of unique customers: {raw_df['customer_id'].n_unique():,}\")\n",
    "print(f\"Number of transactions: {raw_df.height:,}\")\n",
    "print(f\"Total revenue: {raw_df['price'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd9de8",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Train/Test Split Definition\n",
    "\n",
    "We use a temporal split:\n",
    "- **Training**: All transactions up to June 1, 2020\n",
    "- **Test**: July, August, September 2020 (last ~3.5 months)\n",
    "\n",
    "This allows us to evaluate the model's ability to forecast future revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train/test split dates\n",
    "PERIOD_TRAIN_TEST_SPLIT = date(2020, 6, 1)\n",
    "TEST_PERIOD_END = date(2020, 9, 22)  # End of available data\n",
    "\n",
    "print(f\"Training period: up to {PERIOD_TRAIN_TEST_SPLIT}\")\n",
    "print(f\"Test period: {PERIOD_TRAIN_TEST_SPLIT} to {TEST_PERIOD_END}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57393807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for complete months (consistent with hm-transactions.ipynb)\n",
    "# We use data starting from 2018-10-01 for proper cohort assignment\n",
    "# October cohort is excluded later via COHORT_START_DATE filter\n",
    "DATA_START_DATE = date(2018, 10, 1)\n",
    "\n",
    "filtered_df = raw_df.filter(\n",
    "    (pl.col(\"t_dat\") >= DATA_START_DATE) & (pl.col(\"t_dat\") < date(2020, 9, 1))\n",
    ")\n",
    "\n",
    "print(f\"Filtered data shape: {filtered_df.shape}\")\n",
    "date_min = filtered_df[\"t_dat\"].min()\n",
    "date_max = filtered_df[\"t_dat\"].max()\n",
    "print(f\"Date range after filtering: {date_min} to {date_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1911453",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cohort Assignment\n",
    "\n",
    "**Cohort Definition**: A customer's cohort is determined by their **first purchase month**.\n",
    "\n",
    "For example:\n",
    "- Customer who first purchased in November 2018 → Cohort 2018-11-01\n",
    "- Customer who first purchased in March 2019 → Cohort 2019-03-01\n",
    "\n",
    "This groups customers by when they were \"acquired\" by the business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1794e4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign cohorts based on first purchase month\n",
    "customers_with_cohort_df = (\n",
    "    filtered_df.with_columns(pl.col(\"t_dat\").dt.truncate(\"1mo\").alias(\"period\"))\n",
    "    .with_columns(pl.col(\"period\").min().over(\"customer_id\").alias(\"cohort\"))\n",
    "    .sort([\"customer_id\", \"t_dat\"])\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Customers with cohort assigned: {customers_with_cohort_df.height:,} transactions\"\n",
    ")\n",
    "customers_with_cohort_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20eb554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort size summary\n",
    "cohort_sizes = (\n",
    "    customers_with_cohort_df.group_by(\"cohort\")\n",
    "    .agg(\n",
    "        pl.col(\"customer_id\").n_unique().alias(\"n_customers\"),\n",
    "        pl.col(\"price\").sum().alias(\"total_revenue\"),\n",
    "        pl.col(\"t_dat\").count().alias(\"n_transactions\"),\n",
    "    )\n",
    "    .sort(\"cohort\")\n",
    ")\n",
    "\n",
    "print(\"Cohort Summary:\")\n",
    "print(cohort_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc514c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cohort sizes\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "cohort_dates = cohort_sizes[\"cohort\"].to_list()\n",
    "cohort_customers = cohort_sizes[\"n_customers\"].to_list()\n",
    "\n",
    "ax.bar(range(len(cohort_dates)), cohort_customers, color=\"steelblue\", edgecolor=\"black\")\n",
    "ax.set_xticks(range(len(cohort_dates)))\n",
    "ax.set_xticklabels([d.strftime(\"%Y-%m\") for d in cohort_dates], rotation=45, ha=\"right\")\n",
    "ax.set_xlabel(\"Cohort (First Purchase Month)\")\n",
    "ax.set_ylabel(\"Number of Customers\")\n",
    "ax.set_title(\"Customer Count by Cohort\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "for i, n in enumerate(cohort_customers):\n",
    "    ax.text(i, n + 1000, f\"{n:,}\", ha=\"center\", va=\"bottom\", fontsize=8, rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd396d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---\n",
    "## 5. Helper Functions (Data Processing)\n",
    "\n",
    "These functions handle:\n",
    "1. Computing RFM (Recency, Frequency, T, Monetary Value) metrics per customer\n",
    "2. Adding cohort information\n",
    "3. Summarizing cohort statistics for debugging\n",
    "4. Subsampling cohorts if `MAX_COHORT_SIZE` is set\n",
    "\n",
    "**RFM Definitions:**\n",
    "- `frequency`: Number of *repeat* purchases (total purchases - 1)\n",
    "- `recency`: Time between first and last purchase (in days)\n",
    "- `T`: Time between first purchase and observation end (in days)\n",
    "- `monetary_value`: Average spend per transaction (for repeat customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rfm_by_cohort(\n",
    "    transactions_df: pl.DataFrame,\n",
    "    observation_end: date,\n",
    "    time_unit: str = \"D\",\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute RFM metrics with cohort assignment for all customers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions_df : pl.DataFrame\n",
    "        Raw transactions with columns: customer_id, t_dat, price\n",
    "    observation_end : date\n",
    "        End of observation period for T calculation\n",
    "    time_unit : str\n",
    "        Time unit for recency and T: \"D\" (days) or \"W\" (weeks)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pl.DataFrame\n",
    "        Columns: customer_id, frequency, recency, T, monetary_value, cohort\n",
    "    \"\"\"\n",
    "    # Time unit divisor\n",
    "    divisor = {\"D\": 1, \"W\": 7, \"M\": 30}.get(time_unit, 1)\n",
    "\n",
    "    # Compute cohort (first purchase month) and RFM metrics\n",
    "    return (\n",
    "        transactions_df.with_columns(pl.col(\"t_dat\").dt.truncate(\"1mo\").alias(\"period\"))\n",
    "        .group_by(\"customer_id\")\n",
    "        .agg(\n",
    "            pl.col(\"t_dat\").min().alias(\"first_purchase\"),\n",
    "            pl.col(\"t_dat\").max().alias(\"last_purchase\"),\n",
    "            pl.col(\"t_dat\").count().alias(\"n_transactions\"),\n",
    "            pl.col(\"price\").sum().alias(\"total_spend\"),\n",
    "            pl.col(\"period\").min().alias(\"cohort\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            # frequency = number of repeat purchases (total - 1)\n",
    "            (pl.col(\"n_transactions\") - 1).alias(\"frequency\"),\n",
    "            # recency = time between first and last purchase\n",
    "            (\n",
    "                (pl.col(\"last_purchase\") - pl.col(\"first_purchase\"))\n",
    "                .dt.total_days()\n",
    "                .truediv(divisor)\n",
    "            ).alias(\"recency\"),\n",
    "            # T = time between first purchase and observation end\n",
    "            (\n",
    "                (pl.lit(observation_end) - pl.col(\"first_purchase\"))\n",
    "                .dt.total_days()\n",
    "                .truediv(divisor)\n",
    "            ).alias(\"T\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            # monetary_value = average spend per transaction for repeat customers\n",
    "            pl.when(pl.col(\"frequency\") > 0)\n",
    "            .then(pl.col(\"total_spend\") / pl.col(\"n_transactions\"))\n",
    "            .otherwise(0.0)\n",
    "            .alias(\"monetary_value\")\n",
    "        )\n",
    "        .select(\n",
    "            \"customer_id\",\n",
    "            \"frequency\",\n",
    "            \"recency\",\n",
    "            \"T\",\n",
    "            \"monetary_value\",\n",
    "            \"cohort\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29500870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cohort_summary(rfm_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Summarize cohort sizes and repeat customer counts for debugging.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rfm_df : pl.DataFrame\n",
    "        RFM data with cohort column\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pl.DataFrame\n",
    "        Summary with columns: cohort, n_customers, n_repeat, pct_repeat\n",
    "    \"\"\"\n",
    "    return (\n",
    "        rfm_df.group_by(\"cohort\")\n",
    "        .agg(\n",
    "            pl.col(\"customer_id\").count().alias(\"n_customers\"),\n",
    "            (pl.col(\"frequency\") > 0).sum().alias(\"n_repeat\"),\n",
    "            pl.col(\"frequency\").mean().alias(\"avg_frequency\"),\n",
    "            pl.col(\"monetary_value\")\n",
    "            .filter(pl.col(\"frequency\") > 0)\n",
    "            .mean()\n",
    "            .alias(\"avg_monetary\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            (pl.col(\"n_repeat\") / pl.col(\"n_customers\") * 100).alias(\"pct_repeat\")\n",
    "        )\n",
    "        .sort(\"cohort\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b363e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_cohort_if_needed(\n",
    "    rfm_data: pl.DataFrame,\n",
    "    max_size: int | None,\n",
    "    random_seed: int = SEED,\n",
    ") -> tuple[pl.DataFrame, int, bool]:\n",
    "    \"\"\"\n",
    "    Subsample cohort data if it exceeds max_size (without replacement).\n",
    "\n",
    "    Sampling is done WITHOUT replacement to ensure each customer\n",
    "    appears exactly once in the subsampled data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rfm_data : pl.DataFrame\n",
    "        RFM data for a single cohort\n",
    "    max_size : int | None\n",
    "        Maximum cohort size. If None, no subsampling.\n",
    "    random_seed : int\n",
    "        Random seed for reproducible subsampling\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[pl.DataFrame, int, bool]\n",
    "        (subsampled_data, original_size, was_subsampled)\n",
    "    \"\"\"\n",
    "    original_size = rfm_data.height\n",
    "\n",
    "    if max_size is None:\n",
    "        return rfm_data, original_size, False\n",
    "\n",
    "    if rfm_data.height <= max_size:\n",
    "        return rfm_data, original_size, False\n",
    "\n",
    "    # Sample WITHOUT replacement to ensure unique customers\n",
    "    subsampled = rfm_data.sample(n=max_size, seed=random_seed, with_replacement=False)\n",
    "    return subsampled, original_size, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_cohort_data(\n",
    "    rfm_pd: pd.DataFrame,\n",
    "    min_customers: int = 50,\n",
    "    min_repeat_customers: int = 10,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Validate cohort data meets minimum requirements for stable MAP fitting.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rfm_pd : pd.DataFrame\n",
    "        RFM data for a single cohort (pandas DataFrame)\n",
    "    min_customers : int\n",
    "        Minimum number of customers required\n",
    "    min_repeat_customers : int\n",
    "        Minimum number of repeat customers (frequency > 0) required\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if data meets requirements, False otherwise\n",
    "    \"\"\"\n",
    "    n_customers = len(rfm_pd)\n",
    "    n_repeat = (rfm_pd[\"frequency\"] > 0).sum()\n",
    "    return n_customers >= min_customers and n_repeat >= min_repeat_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e14183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_fit_result(model) -> bool:\n",
    "    \"\"\"\n",
    "    Check if model fit produced valid (non-NaN) parameter estimates.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : BetaGeoModel or GammaGammaModel\n",
    "        Fitted PyMC-Marketing model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if all parameters are valid (no NaN/Inf), False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fit_result = model.fit_result\n",
    "        for var_name in fit_result.data_vars:\n",
    "            values = fit_result[var_name].to_numpy()\n",
    "            if np.any(np.isnan(values)) or np.any(np.isinf(values)):\n",
    "                return False\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed6c82f",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Compute RFM Data\n",
    "\n",
    "We compute RFM metrics for the training period (up to the train/test split date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbabb9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter training transactions\n",
    "train_transactions_df = filtered_df.filter(pl.col(\"t_dat\") <= PERIOD_TRAIN_TEST_SPLIT)\n",
    "\n",
    "print(f\"Training transactions: {train_transactions_df.height:,}\")\n",
    "print(f\"Training customers: {train_transactions_df['customer_id'].n_unique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f64a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RFM metrics with cohort assignment\n",
    "train_rfm_df_all = compute_rfm_by_cohort(\n",
    "    transactions_df=train_transactions_df,\n",
    "    observation_end=PERIOD_TRAIN_TEST_SPLIT,\n",
    "    time_unit=\"D\",  # Days for finer granularity\n",
    ")\n",
    "\n",
    "# Filter to only include cohorts from November 2018 onwards\n",
    "# (consistent with hm-transactions.ipynb analysis)\n",
    "COHORT_START_DATE = date(2018, 11, 1)\n",
    "train_rfm_df = train_rfm_df_all.filter(pl.col(\"cohort\") >= COHORT_START_DATE)\n",
    "\n",
    "print(f\"RFM data shape (all cohorts): {train_rfm_df_all.shape}\")\n",
    "print(f\"RFM data shape (filtered cohorts >= {COHORT_START_DATE}): {train_rfm_df.shape}\")\n",
    "train_rfm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492140dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort summary for debugging\n",
    "cohort_summary = get_cohort_summary(train_rfm_df)\n",
    "print(\"Cohort Summary (Training Data):\")\n",
    "print(cohort_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics\n",
    "total_customers = train_rfm_df.height\n",
    "n_repeat = train_rfm_df.filter(pl.col(\"frequency\") > 0).height\n",
    "n_single = train_rfm_df.filter(pl.col(\"frequency\") == 0).height\n",
    "\n",
    "print(\"\\nOverall Statistics:\")\n",
    "print(f\"  Total customers: {total_customers:,}\")\n",
    "print(f\"  Repeat customers: {n_repeat:,} ({n_repeat / total_customers:.1%})\")\n",
    "print(f\"  Single-purchase customers: {n_single:,} ({n_single / total_customers:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7723f79f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---\n",
    "## 7. Helper Functions (Model Fitting)\n",
    "\n",
    "These functions fit the BG/NBD and Gamma-Gamma models for each cohort.\n",
    "\n",
    "**Key design decisions:**\n",
    "\n",
    "- Use MAP estimation by default for speed (MCMC available via `fit_method=\"mcmc\"`)\n",
    "- Gamma-Gamma requires repeat customers only (frequency > 0)\n",
    "- Automatically subsamples if `MAX_COHORT_SIZE` is set\n",
    "- Returns dict with models + metadata for later inspection\n",
    "\n",
    "**Debugging tips:**\n",
    "\n",
    "- Set `MAX_COHORT_SIZE=10000` for faster iteration during development\n",
    "- Set `verbose=True` to see progress and subsampling status\n",
    "- Check `result['n_repeat']` if Gamma-Gamma fails (need repeat customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_single_cohort(  # noqa: C901\n",
    "    cohort_id: date,\n",
    "    rfm_data: pl.DataFrame,\n",
    "    fit_method: str = \"map\",\n",
    "    sampler_kwargs: dict[str, Any] | None = None,\n",
    "    max_cohort_size: int | None = MAX_COHORT_SIZE,\n",
    "    min_customers: int = 50,\n",
    "    min_repeat_customers: int = 10,\n",
    "    model_config: dict[str, Prior] | None = None,\n",
    "    *,\n",
    "    verbose: bool = True,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Fit BG/NBD and Gamma-Gamma models for a single cohort.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cohort_id : date\n",
    "        The cohort identifier (first purchase month)\n",
    "    rfm_data : pl.DataFrame\n",
    "        RFM data for this cohort (Polars DataFrame)\n",
    "    fit_method : str\n",
    "        Fitting method: \"map\" for MAP estimation, \"mcmc\" for full MCMC\n",
    "    sampler_kwargs : dict | None\n",
    "        Additional kwargs for the sampler (used with fit_method=\"mcmc\")\n",
    "    max_cohort_size : int | None\n",
    "        If not None, subsample cohort to this size before fitting\n",
    "    min_customers : int\n",
    "        Minimum number of customers required for fitting\n",
    "    min_repeat_customers : int\n",
    "        Minimum number of repeat customers required for Gamma-Gamma\n",
    "    model_config : dict | None\n",
    "        Model configuration with priors. If None, uses BG_NBD_MODEL_CONFIG\n",
    "    verbose : bool\n",
    "        If True, print progress messages\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Keys: 'bgm', 'ggm', 'rfm_data', 'n_customers', 'n_repeat',\n",
    "              'original_size', 'was_subsampled', 'fit_time', 'success'\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Subsample if needed\n",
    "    rfm_subsampled, original_size, was_subsampled = subsample_cohort_if_needed(\n",
    "        rfm_data, max_cohort_size\n",
    "    )\n",
    "\n",
    "    # Convert to pandas for PyMC-Marketing\n",
    "    rfm_pd = rfm_subsampled.to_pandas()\n",
    "\n",
    "    # Add small epsilon to monetary_value to avoid numerical issues with MAP\n",
    "    eps = 1e-6\n",
    "    rfm_pd[\"monetary_value\"] = rfm_pd[\"monetary_value\"].clip(lower=eps)\n",
    "\n",
    "    n_customers = len(rfm_pd)\n",
    "    n_repeat = int((rfm_pd[\"frequency\"] > 0).sum())\n",
    "\n",
    "    if verbose and was_subsampled:\n",
    "        print(f\"    Subsampled from {original_size:,} to {n_customers:,}\")\n",
    "\n",
    "    # Pre-fit data validation\n",
    "    if not validate_cohort_data(rfm_pd, min_customers, min_repeat_customers):\n",
    "        fit_time = time.time() - start_time\n",
    "        return {\n",
    "            \"cohort_id\": cohort_id,\n",
    "            \"bgm\": None,\n",
    "            \"ggm\": None,\n",
    "            \"rfm_data\": rfm_subsampled,\n",
    "            \"rfm_pd\": rfm_pd,\n",
    "            \"n_customers\": n_customers,\n",
    "            \"n_repeat\": n_repeat,\n",
    "            \"original_size\": original_size,\n",
    "            \"was_subsampled\": was_subsampled,\n",
    "            \"fit_time\": fit_time,\n",
    "            \"success\": False,\n",
    "        }\n",
    "\n",
    "    # Use default model config if not provided\n",
    "    bgm_config = model_config if model_config is not None else BG_NBD_MODEL_CONFIG\n",
    "\n",
    "    # Fit BG/NBD model\n",
    "    bgm = None\n",
    "    try:\n",
    "        bgm = BetaGeoModel(data=rfm_pd, model_config=bgm_config)\n",
    "        fit_kwargs = sampler_kwargs.copy() if sampler_kwargs else {}\n",
    "        if fit_method == \"map\":\n",
    "            fit_kwargs.setdefault(\"maxeval\", 5000)\n",
    "            fit_kwargs.setdefault(\"progressbar\", False)\n",
    "        bgm.fit(method=fit_method, **fit_kwargs)\n",
    "\n",
    "        # Validate fit result\n",
    "        if not validate_fit_result(bgm):\n",
    "            bgm = None\n",
    "    except Exception:\n",
    "        bgm = None\n",
    "\n",
    "    # If BG/NBD failed, return early\n",
    "    if bgm is None:\n",
    "        fit_time = time.time() - start_time\n",
    "        return {\n",
    "            \"cohort_id\": cohort_id,\n",
    "            \"bgm\": None,\n",
    "            \"ggm\": None,\n",
    "            \"rfm_data\": rfm_subsampled,\n",
    "            \"rfm_pd\": rfm_pd,\n",
    "            \"n_customers\": n_customers,\n",
    "            \"n_repeat\": n_repeat,\n",
    "            \"original_size\": original_size,\n",
    "            \"was_subsampled\": was_subsampled,\n",
    "            \"fit_time\": fit_time,\n",
    "            \"success\": False,\n",
    "        }\n",
    "\n",
    "    # Fit Gamma-Gamma model (repeat customers only)\n",
    "    ggm = None\n",
    "    repeat_data = rfm_pd[rfm_pd[\"frequency\"] > 0].copy()\n",
    "    if len(repeat_data) >= min_repeat_customers:\n",
    "        repeat_data[\"monetary_value\"] = repeat_data[\"monetary_value\"].clip(lower=eps)\n",
    "        try:\n",
    "            ggm = GammaGammaModel(\n",
    "                data=repeat_data, model_config=GAMMA_GAMMA_MODEL_CONFIG\n",
    "            )\n",
    "            fit_kwargs = sampler_kwargs.copy() if sampler_kwargs else {}\n",
    "            if fit_method == \"map\":\n",
    "                fit_kwargs.setdefault(\"maxeval\", 5000)\n",
    "                fit_kwargs.setdefault(\"progressbar\", False)\n",
    "            ggm.fit(method=fit_method, **fit_kwargs)\n",
    "\n",
    "            # Validate fit result\n",
    "            if not validate_fit_result(ggm):\n",
    "                ggm = None\n",
    "        except Exception:\n",
    "            ggm = None\n",
    "\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    # Success requires both models to fit successfully\n",
    "    success = bgm is not None and ggm is not None\n",
    "\n",
    "    return {\n",
    "        \"cohort_id\": cohort_id,\n",
    "        \"bgm\": bgm,\n",
    "        \"ggm\": ggm,\n",
    "        \"rfm_data\": rfm_subsampled,\n",
    "        \"rfm_pd\": rfm_pd,\n",
    "        \"n_customers\": n_customers,\n",
    "        \"n_repeat\": n_repeat,\n",
    "        \"original_size\": original_size,\n",
    "        \"was_subsampled\": was_subsampled,\n",
    "        \"fit_time\": fit_time,\n",
    "        \"success\": success,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6edf283",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def fit_all_cohorts(\n",
    "    rfm_df: pl.DataFrame,\n",
    "    fit_method: str = \"map\",\n",
    "    sampler_kwargs: dict[str, Any] | None = None,\n",
    "    max_cohort_size: int | None = MAX_COHORT_SIZE,\n",
    "    min_customers: int = 50,\n",
    "    min_repeat_customers: int = 10,\n",
    "    model_config: dict[str, Prior] | None = None,\n",
    "    *,\n",
    "    verbose: bool = True,\n",
    ") -> dict[date, dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fit BG/NBD and Gamma-Gamma models for all cohorts sequentially.\n",
    "\n",
    "    Only returns successful fits (failed cohorts are excluded from results).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rfm_df : pl.DataFrame\n",
    "        RFM data with cohort column\n",
    "    fit_method : str\n",
    "        Fitting method: \"map\" or \"mcmc\"\n",
    "    sampler_kwargs : dict | None\n",
    "        Additional kwargs for the sampler\n",
    "    max_cohort_size : int | None\n",
    "        If not None, subsample each cohort to this size\n",
    "    min_customers : int\n",
    "        Minimum number of customers required for fitting\n",
    "    min_repeat_customers : int\n",
    "        Minimum number of repeat customers required for Gamma-Gamma\n",
    "    model_config : dict | None\n",
    "        Model configuration with priors\n",
    "    verbose : bool\n",
    "        If True, print progress for each cohort\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[date, dict]\n",
    "        Mapping cohort_id -> fit_single_cohort output (only successful fits)\n",
    "    \"\"\"\n",
    "    cohorts = sorted(rfm_df[\"cohort\"].unique().to_list())\n",
    "    n_cohorts = len(cohorts)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Fitting {n_cohorts} cohorts...\")\n",
    "        if max_cohort_size is not None:\n",
    "            print(f\"MAX_COHORT_SIZE = {max_cohort_size:,}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    cohort_results = {}\n",
    "    total_start = time.time()\n",
    "    n_success = 0\n",
    "\n",
    "    for i, cohort_id in enumerate(cohorts, 1):\n",
    "        cohort_rfm = rfm_df.filter(pl.col(\"cohort\") == cohort_id)\n",
    "\n",
    "        if verbose:\n",
    "            n = cohort_rfm.height\n",
    "            print(f\"[{i}/{n_cohorts}] Cohort {cohort_id}: {n:,} customers...\", end=\" \")\n",
    "\n",
    "        result = fit_single_cohort(\n",
    "            cohort_id=cohort_id,\n",
    "            rfm_data=cohort_rfm,\n",
    "            fit_method=fit_method,\n",
    "            sampler_kwargs=sampler_kwargs,\n",
    "            max_cohort_size=max_cohort_size,\n",
    "            min_customers=min_customers,\n",
    "            min_repeat_customers=min_repeat_customers,\n",
    "            model_config=model_config,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Only include successful fits in results\n",
    "        if result[\"success\"]:\n",
    "            cohort_results[cohort_id] = result\n",
    "            n_success += 1\n",
    "\n",
    "        if verbose:\n",
    "            subsample_info = (\n",
    "                f\" (subsampled from {result['original_size']:,})\"\n",
    "                if result[\"was_subsampled\"]\n",
    "                else \"\"\n",
    "            )\n",
    "            n_cust = result[\"n_customers\"]\n",
    "            n_rep = result[\"n_repeat\"]\n",
    "            t = result[\"fit_time\"]\n",
    "            status = \"OK\" if result[\"success\"] else \"SKIPPED\"\n",
    "            msg = f\"{status} in {t:.1f}s - {n_cust:,} cust{subsample_info}, {n_rep:,} repeat\"  # noqa: E501\n",
    "            print(msg)\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "\n",
    "    if verbose:\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Total fitting time: {total_time:.1f}s ({total_time / 60:.1f} min)\")\n",
    "        print(f\"Successful cohorts: {n_success}/{n_cohorts}\")\n",
    "\n",
    "    return cohort_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329fb18",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---\n",
    "## 8. Helper Functions (Predictions)\n",
    "\n",
    "These functions generate CLV predictions and aggregate them across cohorts.\n",
    "\n",
    "**How predictions work:**\n",
    "\n",
    "1. For each cohort, use the fitted BG/NBD model to predict expected purchases\n",
    "2. Use the Gamma-Gamma model to predict expected monetary value per purchase\n",
    "3. CLV = Expected Purchases x Expected Monetary Value\n",
    "4. Aggregate across all cohorts to get total predicted revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cohort_clv(\n",
    "    cohort_result: dict[str, Any],\n",
    "    future_t: float,\n",
    "    discount_rate: float = 0.0,\n",
    "    time_unit: str = \"D\",\n",
    ") -> xr.DataArray | None:\n",
    "    \"\"\"\n",
    "    Compute CLV predictions for a single cohort.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cohort_result : dict\n",
    "        Output from fit_single_cohort()\n",
    "    future_t : float\n",
    "        Future time period in days (or as specified by time_unit)\n",
    "    discount_rate : float\n",
    "        Monthly discount rate (0 = no discounting)\n",
    "    time_unit : str\n",
    "        Time unit of the RFM data: \"D\" (days) or \"W\" (weeks)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray | None\n",
    "        CLV estimates for each customer, or None if no Gamma-Gamma model\n",
    "    \"\"\"\n",
    "    bgm = cohort_result[\"bgm\"]\n",
    "    ggm = cohort_result[\"ggm\"]\n",
    "    rfm_pd = cohort_result[\"rfm_pd\"]\n",
    "\n",
    "    if bgm is None or ggm is None:\n",
    "        return None\n",
    "\n",
    "    # Convert future_t to months for the CLV calculation\n",
    "    # PyMC-Marketing expects future_t in months\n",
    "    days_per_month = 30\n",
    "    future_t_months = future_t / days_per_month\n",
    "\n",
    "    # Compute CLV using Gamma-Gamma method\n",
    "    clv_estimate = ggm.expected_customer_lifetime_value(\n",
    "        transaction_model=bgm,\n",
    "        data=rfm_pd,\n",
    "        future_t=future_t_months,\n",
    "        discount_rate=discount_rate,\n",
    "        time_unit=time_unit,\n",
    "    )\n",
    "\n",
    "    return clv_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b379d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_purchases_by_cohort(\n",
    "    cohort_results: dict[date, dict[str, Any]],\n",
    "    future_t: float,\n",
    ") -> dict[date, xr.DataArray]:\n",
    "    \"\"\"\n",
    "    Compute expected purchases for each cohort.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cohort_results : dict\n",
    "        Output from fit_all_cohorts()\n",
    "    future_t : float\n",
    "        Future time period (in the same units as RFM data)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[date, xr.DataArray]\n",
    "        Expected purchases per cohort\n",
    "    \"\"\"\n",
    "    purchases_by_cohort = {}\n",
    "\n",
    "    for cohort_id, result in cohort_results.items():\n",
    "        bgm = result[\"bgm\"]\n",
    "        if bgm is None:\n",
    "            continue\n",
    "        expected_purchases = bgm.expected_purchases(future_t=future_t)\n",
    "        purchases_by_cohort[cohort_id] = expected_purchases\n",
    "\n",
    "    return purchases_by_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_cohort_clv(\n",
    "    cohort_results: dict[date, dict[str, Any]],\n",
    "    future_t: float,\n",
    "    discount_rate: float = 0.0,\n",
    "    time_unit: str = \"D\",\n",
    "    verbose: bool = True,\n",
    ") -> tuple[xr.DataArray, dict[date, xr.DataArray]]:\n",
    "    \"\"\"\n",
    "    Aggregate CLV predictions across all cohorts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cohort_results : dict\n",
    "        Output from fit_all_cohorts()\n",
    "    future_t : float\n",
    "        Future time period in days\n",
    "    discount_rate : float\n",
    "        Monthly discount rate\n",
    "    time_unit : str\n",
    "        Time unit of RFM data\n",
    "    verbose : bool\n",
    "        Print progress\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[xr.DataArray, dict]\n",
    "        (total_clv across all customers, clv_by_cohort)\n",
    "    \"\"\"\n",
    "    clv_by_cohort = {}\n",
    "    total_clv_list = []\n",
    "\n",
    "    for cohort_id, result in cohort_results.items():\n",
    "        clv_estimate = predict_cohort_clv(\n",
    "            cohort_result=result,\n",
    "            future_t=future_t,\n",
    "            discount_rate=discount_rate,\n",
    "            time_unit=time_unit,\n",
    "        )\n",
    "\n",
    "        if clv_estimate is not None:\n",
    "            clv_by_cohort[cohort_id] = clv_estimate\n",
    "            # Sum across customers for this cohort\n",
    "            cohort_total = clv_estimate.sum(\"customer_id\")\n",
    "            total_clv_list.append(cohort_total)\n",
    "\n",
    "    # Combine all cohort totals\n",
    "    if total_clv_list:\n",
    "        # Stack and sum\n",
    "        total_clv = sum(total_clv_list)\n",
    "    else:\n",
    "        total_clv = None\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Computed CLV for {len(clv_by_cohort)} cohorts\")\n",
    "\n",
    "    return total_clv, clv_by_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c51b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_actual_monthly_revenue(\n",
    "    transactions_df: pl.DataFrame,\n",
    "    start_date: date,\n",
    "    end_date: date,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute actual revenue per month for comparison.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions_df : pl.DataFrame\n",
    "        Raw transactions with t_dat and price columns\n",
    "    start_date : date\n",
    "        Start of period\n",
    "    end_date : date\n",
    "        End of period\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pl.DataFrame\n",
    "        Monthly revenue with columns: month, revenue, n_customers, n_transactions\n",
    "    \"\"\"\n",
    "    monthly_revenue = (\n",
    "        transactions_df.filter(\n",
    "            (pl.col(\"t_dat\") > start_date) & (pl.col(\"t_dat\") <= end_date)\n",
    "        )\n",
    "        .with_columns(pl.col(\"t_dat\").dt.truncate(\"1mo\").alias(\"month\"))\n",
    "        .group_by(\"month\")\n",
    "        .agg(\n",
    "            pl.col(\"price\").sum().alias(\"revenue\"),\n",
    "            pl.col(\"customer_id\").n_unique().alias(\"n_customers\"),\n",
    "            pl.col(\"price\").count().alias(\"n_transactions\"),\n",
    "        )\n",
    "        .sort(\"month\")\n",
    "    )\n",
    "    return monthly_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b96dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cohort_monthly_revenue_predictions(\n",
    "    cohort_result: dict[str, Any],\n",
    "    test_periods: list[date],\n",
    "    observation_end: date,\n",
    ") -> xr.DataArray | None:\n",
    "    \"\"\"\n",
    "    Compute monthly revenue predictions for a single cohort with posterior samples.\n",
    "\n",
    "    This function computes incremental monthly revenue by calculating cumulative\n",
    "    expected revenue at each period end and taking the difference between consecutive\n",
    "    periods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cohort_result : dict\n",
    "        Output from fit_single_cohort() containing 'bgm', 'ggm', 'rfm_pd'\n",
    "    test_periods : list[date]\n",
    "        List of month start dates to predict revenue for\n",
    "    observation_end : date\n",
    "        End of observation period (train/test split date)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray | None\n",
    "        Monthly revenue predictions with dimensions (chain, draw, period),\n",
    "        or None if Gamma-Gamma model is not available\n",
    "    \"\"\"\n",
    "    bgm = cohort_result[\"bgm\"]\n",
    "    ggm = cohort_result[\"ggm\"]\n",
    "    rfm_pd = cohort_result[\"rfm_pd\"]\n",
    "\n",
    "    if bgm is None or ggm is None:\n",
    "        return None\n",
    "\n",
    "    # Get expected spend per customer (posterior samples)\n",
    "    expected_spend = ggm.expected_customer_spend(data=rfm_pd)\n",
    "\n",
    "    # Compute cumulative expected revenue at each period end\n",
    "    cumulative_revenues = []\n",
    "    period_dates = []\n",
    "\n",
    "    for period in test_periods:\n",
    "        # Compute first day of next month (end of current period)\n",
    "        if period.month == 12:\n",
    "            next_month_start = date(period.year + 1, 1, 1)\n",
    "        else:\n",
    "            next_month_start = date(period.year, period.month + 1, 1)\n",
    "\n",
    "        # Days from observation_end to end of this month\n",
    "        days_to_period_end = (next_month_start - observation_end).days\n",
    "\n",
    "        if days_to_period_end <= 0:\n",
    "            continue\n",
    "\n",
    "        # Expected purchases from observation_end to this period\n",
    "        expected_purchases = bgm.expected_purchases(future_t=days_to_period_end)\n",
    "\n",
    "        # Expected revenue = expected_purchases * expected_spend\n",
    "        # Both have dimensions (chain, draw, customer_id)\n",
    "        cumulative_revenue = expected_purchases * expected_spend\n",
    "\n",
    "        # Sum across customers to get cohort-level\n",
    "        cohort_cumulative = cumulative_revenue.sum(\"customer_id\")\n",
    "\n",
    "        cumulative_revenues.append(cohort_cumulative)\n",
    "        period_dates.append(period)\n",
    "\n",
    "    if not cumulative_revenues:\n",
    "        return None\n",
    "\n",
    "    # Compute incremental monthly revenue by differencing\n",
    "    monthly_revenues = []\n",
    "    for i, (cum_rev, period) in enumerate(\n",
    "        zip(cumulative_revenues, period_dates, strict=True)\n",
    "    ):\n",
    "        # First period: all cumulative, else: difference from previous\n",
    "        monthly_rev = cum_rev if i == 0 else cum_rev - cumulative_revenues[i - 1]\n",
    "\n",
    "        # Add period dimension\n",
    "        monthly_revenues.append(monthly_rev.expand_dims({\"period\": [period]}))\n",
    "\n",
    "    # Concatenate along period dimension\n",
    "    all_monthly = xr.concat(monthly_revenues, dim=\"period\")\n",
    "\n",
    "    return all_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_actual_revenue_by_cohort(\n",
    "    transactions_df: pl.DataFrame,\n",
    "    cohorts: list[date],\n",
    "    data_start: date,\n",
    "    data_end: date,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute actual monthly revenue per cohort from transaction data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions_df : pl.DataFrame\n",
    "        Raw transactions with columns: customer_id, t_dat, price\n",
    "    cohorts : list[date]\n",
    "        List of cohort dates to include\n",
    "    data_start : date\n",
    "        Start of data range\n",
    "    data_end : date\n",
    "        End of data range\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pl.DataFrame\n",
    "        DataFrame with columns: cohort, period, revenue\n",
    "    \"\"\"\n",
    "    # Assign cohorts and periods to transactions\n",
    "    revenue_by_cohort = (\n",
    "        transactions_df.filter(\n",
    "            (pl.col(\"t_dat\") >= data_start) & (pl.col(\"t_dat\") < data_end)\n",
    "        )\n",
    "        .with_columns(pl.col(\"t_dat\").dt.truncate(\"1mo\").alias(\"period\"))\n",
    "        # Get first purchase date per customer to determine cohort\n",
    "        .with_columns(\n",
    "            pl.col(\"t_dat\").min().over(\"customer_id\").dt.truncate(\"1mo\").alias(\"cohort\")\n",
    "        )\n",
    "        # Filter to only include specified cohorts\n",
    "        .filter(pl.col(\"cohort\").is_in(cohorts))\n",
    "        # Exclude acquisition month (cohort_age == 0) - only include repeat revenue\n",
    "        # CLV models predict repeat purchases, not initial acquisition\n",
    "        .filter(pl.col(\"period\") > pl.col(\"cohort\"))\n",
    "        # Aggregate revenue per cohort and period\n",
    "        .group_by([\"cohort\", \"period\"])\n",
    "        .agg(pl.col(\"price\").sum().alias(\"revenue\"))\n",
    "        .sort([\"cohort\", \"period\"])\n",
    "    )\n",
    "\n",
    "    return revenue_by_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe566f9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def compute_actual_aggregate_revenue(\n",
    "    transactions_df: pl.DataFrame,\n",
    "    training_cohorts: list[date],\n",
    "    data_start: date,\n",
    "    data_end: date,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute actual aggregate monthly revenue for training cohorts.\n",
    "\n",
    "    This function computes revenue with proper filtering to match the reference\n",
    "    notebook (hm-transactions.ipynb):\n",
    "    - Only transactions from customers in training cohorts\n",
    "    - Only repeat purchases (cohort_age > 0, excludes acquisition month)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions_df : pl.DataFrame\n",
    "        Raw transactions with columns: customer_id, t_dat, price\n",
    "    training_cohorts : list[date]\n",
    "        List of cohort dates included in training\n",
    "    data_start : date\n",
    "        Start of data range\n",
    "    data_end : date\n",
    "        End of data range\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pl.DataFrame\n",
    "        DataFrame with columns: month, revenue\n",
    "    \"\"\"\n",
    "    return (\n",
    "        transactions_df.filter(\n",
    "            (pl.col(\"t_dat\") >= data_start) & (pl.col(\"t_dat\") < data_end)\n",
    "        )\n",
    "        .with_columns(pl.col(\"t_dat\").dt.truncate(\"1mo\").alias(\"month\"))\n",
    "        # Assign cohort based on first purchase date\n",
    "        .with_columns(\n",
    "            pl.col(\"t_dat\").min().over(\"customer_id\").dt.truncate(\"1mo\").alias(\"cohort\")\n",
    "        )\n",
    "        # Filter for training cohorts only\n",
    "        .filter(pl.col(\"cohort\").is_in(training_cohorts))\n",
    "        # Exclude acquisition month (cohort_age > 0)\n",
    "        .filter(pl.col(\"month\") > pl.col(\"cohort\"))\n",
    "        # Aggregate revenue per month\n",
    "        .group_by(\"month\")\n",
    "        .agg(pl.col(\"price\").sum().alias(\"revenue\"))\n",
    "        .sort(\"month\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c7979",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---\n",
    "## 9. Helper Functions (Visualization)\n",
    "\n",
    "These functions create diagnostic and comparison plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd699958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cohort_parameter_comparison(\n",
    "    cohort_results: dict[date, dict[str, Any]],\n",
    "    param_name: str = \"alpha\",\n",
    "    model_type: str = \"bgm\",\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot parameter values across cohorts for comparison.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cohort_results : dict\n",
    "        Output from fit_all_cohorts()\n",
    "    param_name : str\n",
    "        Parameter name to plot (e.g., \"alpha\", \"r\", \"a\", \"b\" for BG/NBD)\n",
    "    model_type : str\n",
    "        \"bgm\" for BG/NBD or \"ggm\" for Gamma-Gamma\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "    \"\"\"\n",
    "    cohorts = []\n",
    "    values = []\n",
    "\n",
    "    for cohort_id, result in sorted(cohort_results.items()):\n",
    "        model = result[model_type]\n",
    "        if model is not None:\n",
    "            try:\n",
    "                # Get MAP estimate\n",
    "                fit_result = model.fit_result\n",
    "                if param_name in fit_result:\n",
    "                    val = float(fit_result[param_name].to_numpy().mean())\n",
    "                    cohorts.append(cohort_id)\n",
    "                    values.append(val)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.bar(range(len(cohorts)), values, color=\"steelblue\", edgecolor=\"black\")\n",
    "    ax.set_xticks(range(len(cohorts)))\n",
    "    ax.set_xticklabels([d.strftime(\"%Y-%m\") for d in cohorts], rotation=45, ha=\"right\")\n",
    "    ax.set_xlabel(\"Cohort\")\n",
    "    ax.set_ylabel(param_name)\n",
    "    ax.set_title(\n",
    "        f\"{model_type.upper()} Parameter '{param_name}' by Cohort\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05328a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clv_distribution_by_cohort(\n",
    "    clv_by_cohort: dict[date, xr.DataArray],\n",
    "    n_cohorts_to_show: int = 6,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot CLV distributions for a subset of cohorts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clv_by_cohort : dict\n",
    "        CLV estimates per cohort from aggregate_cohort_clv()\n",
    "    n_cohorts_to_show : int\n",
    "        Number of cohorts to display\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "    \"\"\"\n",
    "    cohorts = sorted(clv_by_cohort.keys())\n",
    "    # Select evenly spaced cohorts\n",
    "    step = max(1, len(cohorts) // n_cohorts_to_show)\n",
    "    selected_cohorts = cohorts[::step][:n_cohorts_to_show]\n",
    "\n",
    "    n_rows = (len(selected_cohorts) + 1) // 2\n",
    "    fig, axes = plt.subplots(n_rows, 2, figsize=(14, 4 * n_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, cohort_id in enumerate(selected_cohorts):\n",
    "        ax = axes[i]\n",
    "        clv_data = clv_by_cohort[cohort_id]\n",
    "        clv_mean = clv_data.mean((\"chain\", \"draw\")).to_numpy()\n",
    "        clv_capped = np.clip(clv_mean, 0, np.percentile(clv_mean, 99))\n",
    "\n",
    "        ax.hist(clv_capped, bins=50, edgecolor=\"black\", alpha=0.7)\n",
    "        ax.axvline(\n",
    "            clv_mean.mean(),\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Mean: {clv_mean.mean():.4f}\",\n",
    "        )\n",
    "        ax.set_xlabel(\"CLV\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(f\"Cohort {cohort_id.strftime('%Y-%m')}\")\n",
    "        ax.legend()\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(len(selected_cohorts), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    fig.suptitle(\"CLV Distribution by Cohort\", fontsize=16, fontweight=\"bold\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_vs_actual_revenue(\n",
    "    predicted_total: float,\n",
    "    predicted_hdi: tuple[float, float],\n",
    "    actual_total: float,\n",
    "    title: str = \"Predicted vs Actual Revenue\",\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot predicted vs actual total revenue.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predicted_total : float\n",
    "        Predicted total revenue (mean)\n",
    "    predicted_hdi : tuple\n",
    "        (lower, upper) bounds of HDI\n",
    "    actual_total : float\n",
    "        Actual total revenue\n",
    "    title : str\n",
    "        Plot title\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Predicted\n",
    "    ax.bar(\n",
    "        0,\n",
    "        predicted_total,\n",
    "        yerr=[\n",
    "            [predicted_total - predicted_hdi[0]],\n",
    "            [predicted_hdi[1] - predicted_total],\n",
    "        ],\n",
    "        capsize=10,\n",
    "        color=\"C0\",\n",
    "        alpha=0.7,\n",
    "        label=\"Predicted\",\n",
    "    )\n",
    "\n",
    "    # Actual\n",
    "    ax.bar(1, actual_total, color=\"C1\", alpha=0.7, label=\"Actual\")\n",
    "\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels([\"Predicted\", \"Actual\"])\n",
    "    ax.set_ylabel(\"Total Revenue\")\n",
    "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "    ax.legend()\n",
    "\n",
    "    # Add value labels\n",
    "    ax.text(\n",
    "        0,\n",
    "        predicted_total + (predicted_hdi[1] - predicted_total) * 1.1,\n",
    "        f\"{predicted_total:,.0f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "    ax.text(1, actual_total * 1.02, f\"{actual_total:,.0f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2f91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_monthly_revenue_predictions(\n",
    "    cohort_results: dict[date, dict[str, Any]],\n",
    "    periods: list[date],\n",
    "    observation_end: date,\n",
    "    verbose: bool = True,\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Compute monthly revenue predictions with full posterior samples.\n",
    "\n",
    "    For each month, computes the cumulative CLV up to that month and then\n",
    "    takes the difference to get monthly revenue.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cohort_results : dict\n",
    "        Output from fit_all_cohorts()\n",
    "    periods : list[date]\n",
    "        List of month start dates to predict revenue for\n",
    "    observation_end : date\n",
    "        End of observation period (train/test split date)\n",
    "    verbose : bool\n",
    "        Print progress\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        Monthly revenue predictions with dimensions (chain, draw, period)\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Computing monthly predictions for {len(periods)} periods...\")\n",
    "\n",
    "    monthly_predictions = []\n",
    "\n",
    "    for period in periods:\n",
    "        # Days from observation_end to end of this month\n",
    "        # Use middle of month for CLV calculation\n",
    "        days_to_period_end = (period - observation_end).days + 15\n",
    "\n",
    "        if days_to_period_end <= 0:\n",
    "            # This is a training period - we need cumulative CLV\n",
    "            # For training, compute from start of data to this period\n",
    "            continue\n",
    "\n",
    "        period_clv_total = None\n",
    "\n",
    "        for cohort_id, result in cohort_results.items():\n",
    "            ggm = result[\"ggm\"]\n",
    "            bgm = result[\"bgm\"]\n",
    "            rfm_pd = result[\"rfm_pd\"]\n",
    "\n",
    "            if bgm is None or ggm is None:\n",
    "                continue\n",
    "\n",
    "            # CLV for this cohort up to this period\n",
    "            future_t_months = days_to_period_end / 30\n",
    "\n",
    "            try:\n",
    "                clv = ggm.expected_customer_lifetime_value(\n",
    "                    transaction_model=bgm,\n",
    "                    data=rfm_pd,\n",
    "                    future_t=future_t_months,\n",
    "                    discount_rate=0.0,\n",
    "                    time_unit=\"D\",\n",
    "                )\n",
    "                # Sum across customers for this cohort\n",
    "                cohort_total = clv.sum(\"customer_id\")\n",
    "\n",
    "                if period_clv_total is None:\n",
    "                    period_clv_total = cohort_total\n",
    "                else:\n",
    "                    period_clv_total = period_clv_total + cohort_total\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  Warning: Failed for cohort {cohort_id}: {e}\")\n",
    "\n",
    "        if period_clv_total is not None:\n",
    "            monthly_predictions.append(\n",
    "                period_clv_total.expand_dims({\"period\": [period]})\n",
    "            )\n",
    "\n",
    "    if not monthly_predictions:\n",
    "        raise ValueError(\"No predictions computed\")\n",
    "\n",
    "    # Concatenate along period dimension\n",
    "    all_predictions = xr.concat(monthly_predictions, dim=\"period\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"  Computed predictions for {len(monthly_predictions)} periods\")\n",
    "\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_train_revenue_predictions(\n",
    "    cohort_results: dict[date, dict[str, Any]],\n",
    "    transactions_df: pl.DataFrame,\n",
    "    train_periods: list[date],\n",
    "    data_start: date,\n",
    "    verbose: bool = True,\n",
    ") -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    Compute revenue predictions for training periods using in-sample fit.\n",
    "\n",
    "    For training data, we compute CLV from each cohort's start to each period.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cohort_results : dict\n",
    "        Output from fit_all_cohorts()\n",
    "    transactions_df : pl.DataFrame\n",
    "        Training transactions data\n",
    "    train_periods : list[date]\n",
    "        List of month start dates in training period\n",
    "    data_start : date\n",
    "        Start of data\n",
    "    verbose : bool\n",
    "        Print progress\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        Monthly revenue predictions with dimensions (chain, draw, period)\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Computing training period predictions for {len(train_periods)} periods...\"\n",
    "        )\n",
    "\n",
    "    monthly_predictions = []\n",
    "\n",
    "    for period in train_periods:\n",
    "        period_clv_total = None\n",
    "\n",
    "        for cohort_id, result in cohort_results.items():\n",
    "            # Only include cohorts that existed before this period\n",
    "            if cohort_id > period:\n",
    "                continue\n",
    "\n",
    "            ggm = result[\"ggm\"]\n",
    "            bgm = result[\"bgm\"]\n",
    "            rfm_pd = result[\"rfm_pd\"]\n",
    "\n",
    "            if ggm is None:\n",
    "                continue\n",
    "\n",
    "            # Days from cohort start to end of this period\n",
    "            # Approximate: use days from observation start (when RFM was computed)\n",
    "            # For training fit, we use T + small future window\n",
    "            days_since_cohort = (period - cohort_id).days + 15\n",
    "\n",
    "            # Use a small future_t relative to the cohort age\n",
    "            future_t_months = max(\n",
    "                0.5, days_since_cohort / 30 / 12\n",
    "            )  # fraction of cohort age\n",
    "\n",
    "            try:\n",
    "                clv = ggm.expected_customer_lifetime_value(\n",
    "                    transaction_model=bgm,\n",
    "                    data=rfm_pd,\n",
    "                    future_t=future_t_months,\n",
    "                    discount_rate=0.0,\n",
    "                    time_unit=\"D\",\n",
    "                )\n",
    "                cohort_total = clv.sum(\"customer_id\")\n",
    "\n",
    "                if period_clv_total is None:\n",
    "                    period_clv_total = cohort_total\n",
    "                else:\n",
    "                    period_clv_total = period_clv_total + cohort_total\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if period_clv_total is not None:\n",
    "            monthly_predictions.append(\n",
    "                period_clv_total.expand_dims({\"period\": [period]})\n",
    "            )\n",
    "\n",
    "    if monthly_predictions:\n",
    "        return xr.concat(monthly_predictions, dim=\"period\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a50d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_revenue_over_time(\n",
    "    actual_revenue: pl.DataFrame,\n",
    "    test_predictions: xr.DataArray | None = None,\n",
    "    train_test_split: date | None = None,\n",
    "    hdi_probs: tuple[float, float] = (0.5, 0.94),\n",
    "    figsize: tuple[int, int] = (14, 7),\n",
    "    title: str = \"Total Revenue (Training Cohorts)\",\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot actual vs predicted revenue over time with HDI bands.\n",
    "\n",
    "    Creates a visualization similar to the reference showing:\n",
    "    - Actual revenue as black dots connected by lines\n",
    "    - Posterior predictive mean and HDI bands\n",
    "    - Train/test split vertical line\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual_revenue : pl.DataFrame\n",
    "        Actual monthly revenue with columns: month, revenue\n",
    "    test_predictions : xr.DataArray | None\n",
    "        Predictions with dimensions (chain, draw, period) for test periods\n",
    "    train_test_split : date | None\n",
    "        Date of train/test split for vertical line\n",
    "    hdi_probs : tuple\n",
    "        HDI probability levels (inner, outer), e.g., (0.5, 0.94)\n",
    "    figsize : tuple\n",
    "        Figure size\n",
    "    title : str\n",
    "        Plot title\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Get actual data\n",
    "    actual_months = actual_revenue[\"month\"].to_list()\n",
    "    actual_values = actual_revenue[\"revenue\"].to_list()\n",
    "\n",
    "    # Plot actual values\n",
    "    ax.plot(\n",
    "        actual_months,\n",
    "        actual_values,\n",
    "        \"o-\",\n",
    "        color=\"black\",\n",
    "        linewidth=1.5,\n",
    "        markersize=6,\n",
    "        label=\"Actual\",\n",
    "        zorder=10,\n",
    "    )\n",
    "\n",
    "    # Identify test periods\n",
    "    if train_test_split is not None:\n",
    "        test_months = [m for m in actual_months if m >= train_test_split]\n",
    "    else:\n",
    "        test_months = []\n",
    "\n",
    "    # Plot test predictions with HDI bands\n",
    "    if test_predictions is not None and len(test_months) > 0:\n",
    "        test_periods = test_predictions.coords[\"period\"].to_numpy()\n",
    "        test_periods_dt = [pd.Timestamp(p).date() for p in test_periods]\n",
    "\n",
    "        # Get posterior samples and reshape\n",
    "        if test_predictions.ndim > 1:\n",
    "            # Reshape to (n_samples, n_periods)\n",
    "            n_periods = len(test_periods)\n",
    "            samples_2d = test_predictions.to_numpy()\n",
    "            if samples_2d.ndim == 3:  # (chain, draw, period)\n",
    "                samples_2d = samples_2d.reshape(-1, n_periods)\n",
    "            elif samples_2d.ndim == 2:  # (draw, period) or similar\n",
    "                pass\n",
    "            else:\n",
    "                samples_2d = samples_2d.reshape(-1, n_periods)\n",
    "\n",
    "            # Compute statistics per period\n",
    "            means = samples_2d.mean(axis=0)\n",
    "            hdi_inner = np.array(\n",
    "                [\n",
    "                    az.hdi(samples_2d[:, i], hdi_prob=hdi_probs[0])\n",
    "                    for i in range(n_periods)\n",
    "                ]\n",
    "            )\n",
    "            hdi_outer = np.array(\n",
    "                [\n",
    "                    az.hdi(samples_2d[:, i], hdi_prob=hdi_probs[1])\n",
    "                    for i in range(n_periods)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # Plot HDI bands for test period (orange)\n",
    "            ax.fill_between(\n",
    "                test_periods_dt,\n",
    "                hdi_outer[:, 0],\n",
    "                hdi_outer[:, 1],\n",
    "                alpha=0.3,\n",
    "                color=\"C1\",\n",
    "                label=f\"{int(hdi_probs[1] * 100)}% HDI (test)\",\n",
    "            )\n",
    "            ax.fill_between(\n",
    "                test_periods_dt,\n",
    "                hdi_inner[:, 0],\n",
    "                hdi_inner[:, 1],\n",
    "                alpha=0.5,\n",
    "                color=\"C1\",\n",
    "                label=f\"{int(hdi_probs[0] * 100)}% HDI (test)\",\n",
    "            )\n",
    "            ax.plot(\n",
    "                test_periods_dt,\n",
    "                means,\n",
    "                \"-\",\n",
    "                color=\"C1\",\n",
    "                linewidth=2,\n",
    "                label=\"Posterior mean (test)\",\n",
    "            )\n",
    "\n",
    "    # Add train/test split line\n",
    "    if train_test_split is not None:\n",
    "        ax.axvline(\n",
    "            train_test_split - pd.DateOffset(months=1),\n",
    "            color=\"gray\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=1.5,\n",
    "            label=\"Train/test split\",\n",
    "        )\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_xlabel(\"Period\", fontsize=12)\n",
    "    ax.set_ylabel(\"Revenue\", fontsize=12)\n",
    "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    # Format x-axis\n",
    "    ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Legend\n",
    "    ax.legend(loc=\"upper left\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_revenue_train_test(\n",
    "    transactions_df: pl.DataFrame,\n",
    "    cohort_results: dict[date, dict[str, Any]],\n",
    "    train_test_split: date,\n",
    "    test_end: date,\n",
    "    data_start: date,\n",
    "    hdi_probs: tuple[float, float] = (0.5, 0.94),\n",
    "    figsize: tuple[int, int] = (14, 7),\n",
    "    title: str = \"Total Revenue (Training Cohorts)\",\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create the full revenue over time plot with train/test split.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    transactions_df : pl.DataFrame\n",
    "        All transactions data\n",
    "    cohort_results : dict\n",
    "        Output from fit_all_cohorts()\n",
    "    train_test_split : date\n",
    "        Date of train/test split\n",
    "    test_end : date\n",
    "        End of test period\n",
    "    data_start : date\n",
    "        Start of data\n",
    "    hdi_probs : tuple\n",
    "        HDI probability levels\n",
    "    figsize : tuple\n",
    "        Figure size\n",
    "    title : str\n",
    "        Plot title\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "    \"\"\"\n",
    "    # Get training cohorts from cohort_results\n",
    "    training_cohorts = list(cohort_results.keys())\n",
    "\n",
    "    # Compute actual monthly revenue with proper filtering:\n",
    "    # - Only transactions from customers in training cohorts\n",
    "    # - Only repeat purchases (cohort_age > 0, excludes acquisition month)\n",
    "    actual_monthly = compute_actual_aggregate_revenue(\n",
    "        transactions_df=transactions_df,\n",
    "        training_cohorts=training_cohorts,\n",
    "        data_start=data_start,\n",
    "        data_end=test_end,\n",
    "    )\n",
    "\n",
    "    # Get test periods\n",
    "    test_periods = [\n",
    "        d\n",
    "        for d in actual_monthly[\"month\"].to_list()\n",
    "        if d >= train_test_split and d < test_end\n",
    "    ]\n",
    "\n",
    "    # Compute test predictions\n",
    "    print(\"Computing test period predictions...\")\n",
    "    test_predictions = compute_monthly_revenue_predictions(\n",
    "        cohort_results=cohort_results,\n",
    "        periods=test_periods,\n",
    "        observation_end=train_test_split,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Create plot\n",
    "    fig = plot_revenue_over_time(\n",
    "        actual_revenue=actual_monthly,\n",
    "        test_predictions=test_predictions,\n",
    "        train_test_split=train_test_split,\n",
    "        hdi_probs=hdi_probs,\n",
    "        figsize=figsize,\n",
    "        title=title,\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c70bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cohort_revenue_predictions(\n",
    "    cohort_results: dict[date, dict[str, Any]],\n",
    "    transactions_df: pl.DataFrame,\n",
    "    cohorts_to_plot: list[date],\n",
    "    train_test_split: date,\n",
    "    test_end: date,\n",
    "    data_start: date,\n",
    "    hdi_prob: float = 0.94,\n",
    "    figsize: tuple[int, int] = (15, 21),\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Create faceted revenue prediction plots per cohort.\n",
    "\n",
    "    This function creates a figure with one subplot per cohort showing:\n",
    "    - Training period: observed revenue (blue line with markers)\n",
    "    - Test period: HDI bands + posterior mean + observed revenue (orange)\n",
    "    - Train/test split vertical line\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cohort_results : dict\n",
    "        Output from fit_all_cohorts()\n",
    "    transactions_df : pl.DataFrame\n",
    "        All transactions data with columns: customer_id, t_dat, price\n",
    "    cohorts_to_plot : list[date]\n",
    "        List of cohort dates to include in the plot\n",
    "    train_test_split : date\n",
    "        Date of train/test split\n",
    "    test_end : date\n",
    "        End of test period\n",
    "    data_start : date\n",
    "        Start of data range\n",
    "    hdi_prob : float\n",
    "        HDI probability level (default 0.94)\n",
    "    figsize : tuple\n",
    "        Figure size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "    \"\"\"\n",
    "    n_cohorts = len(cohorts_to_plot)\n",
    "\n",
    "    if n_cohorts == 0:\n",
    "        raise ValueError(\"No cohorts to plot\")\n",
    "\n",
    "    # Get test periods\n",
    "    test_periods = []\n",
    "    current = train_test_split\n",
    "    while current < test_end:\n",
    "        test_periods.append(current)\n",
    "        # Move to next month\n",
    "        if current.month == 12:\n",
    "            current = date(current.year + 1, 1, 1)\n",
    "        else:\n",
    "            current = date(current.year, current.month + 1, 1)\n",
    "\n",
    "    # Compute actual revenue by cohort (for all cohorts, not just fitted ones)\n",
    "    actual_revenue = compute_actual_revenue_by_cohort(\n",
    "        transactions_df=transactions_df,\n",
    "        cohorts=cohorts_to_plot,\n",
    "        data_start=data_start,\n",
    "        data_end=test_end,\n",
    "    )\n",
    "\n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=n_cohorts,\n",
    "        ncols=1,\n",
    "        figsize=figsize,\n",
    "        sharex=True,\n",
    "        sharey=False,\n",
    "        layout=\"constrained\",\n",
    "    )\n",
    "\n",
    "    # Handle single cohort case\n",
    "    if n_cohorts == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for cohort_id, ax in zip(cohorts_to_plot, axes, strict=True):\n",
    "        cohort_name = cohort_id.isoformat()\n",
    "\n",
    "        # Get actual revenue for this cohort\n",
    "        cohort_actual = actual_revenue.filter(pl.col(\"cohort\") == cohort_id)\n",
    "\n",
    "        # Training data: before train_test_split\n",
    "        train_actual = cohort_actual.filter(pl.col(\"period\") < train_test_split)\n",
    "        if train_actual.height > 0:\n",
    "            ax.plot(\n",
    "                train_actual[\"period\"].to_list(),\n",
    "                train_actual[\"revenue\"].to_list(),\n",
    "                \"o-\",\n",
    "                color=\"C0\",\n",
    "                linewidth=1.5,\n",
    "                markersize=5,\n",
    "                label=\"observed revenue (train)\",\n",
    "            )\n",
    "\n",
    "        # Test data: at or after train_test_split\n",
    "        test_actual = cohort_actual.filter(pl.col(\"period\") >= train_test_split)\n",
    "\n",
    "        # Compute predictions for this cohort (only if model exists)\n",
    "        predictions = None\n",
    "        if cohort_id in cohort_results:\n",
    "            result = cohort_results[cohort_id]\n",
    "            predictions = compute_cohort_monthly_revenue_predictions(\n",
    "                cohort_result=result,\n",
    "                test_periods=test_periods,\n",
    "                observation_end=train_test_split,\n",
    "            )\n",
    "\n",
    "        if predictions is not None:\n",
    "            # Get prediction periods and values\n",
    "            pred_periods = [\n",
    "                pd.Timestamp(p).date() for p in predictions.coords[\"period\"].to_numpy()\n",
    "            ]\n",
    "            n_periods = len(pred_periods)\n",
    "\n",
    "            # Stack chain and draw dimensions, keeping period separate\n",
    "            # predictions has dims: (chain, draw, period) or similar\n",
    "            stacked = predictions.stack(sample=(\"chain\", \"draw\"))\n",
    "            # Now shape is (period, sample) - transpose to (sample, period)\n",
    "            samples_2d = stacked.transpose(\"sample\", \"period\").to_numpy()\n",
    "\n",
    "            # Compute mean and HDI per period\n",
    "            means = samples_2d.mean(axis=0)\n",
    "            hdi_values = np.array(\n",
    "                [az.hdi(samples_2d[:, i], hdi_prob=hdi_prob) for i in range(n_periods)]\n",
    "            )\n",
    "\n",
    "            # Plot HDI band (test)\n",
    "            ax.fill_between(\n",
    "                pred_periods,\n",
    "                hdi_values[:, 0],\n",
    "                hdi_values[:, 1],\n",
    "                alpha=0.3,\n",
    "                color=\"C1\",\n",
    "                label=f\"{int(hdi_prob * 100)}% HDI (test)\",\n",
    "            )\n",
    "\n",
    "            # Plot posterior mean (test)\n",
    "            ax.plot(\n",
    "                pred_periods,\n",
    "                means,\n",
    "                \"-\",\n",
    "                color=\"C1\",\n",
    "                linewidth=2,\n",
    "                label=\"posterior mean (test)\",\n",
    "            )\n",
    "\n",
    "        # Plot observed test revenue\n",
    "        if test_actual.height > 0:\n",
    "            ax.plot(\n",
    "                test_actual[\"period\"].to_list(),\n",
    "                test_actual[\"revenue\"].to_list(),\n",
    "                \"o\",\n",
    "                color=\"C1\",\n",
    "                markersize=6,\n",
    "                label=\"observed revenue (test)\",\n",
    "            )\n",
    "\n",
    "        # Add train/test split line\n",
    "        ax.axvline(\n",
    "            train_test_split - pd.DateOffset(months=1),\n",
    "            color=\"black\",\n",
    "            linestyle=\"--\",\n",
    "            linewidth=1.5,\n",
    "            label=\"train/pred split\",\n",
    "        )\n",
    "\n",
    "        # Format subplot\n",
    "        ax.set_ylabel(\"Revenue\")\n",
    "        ax.set_title(f\"Revenue - Cohort {cohort_name}\")\n",
    "        ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # Set common x-label on bottom subplot\n",
    "    axes[-1].set_xlabel(\"period\")\n",
    "\n",
    "    # Format x-axis dates\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    # Add supertitle\n",
    "    fig.suptitle(\"Revenue Predictions\", y=1.03, fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe122008",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Model Fitting\n",
    "\n",
    "Now we fit BG/NBD and Gamma-Gamma models for each cohort.\n",
    "\n",
    "**Expected runtime:**\n",
    "- With `MAX_COHORT_SIZE = 10000`: ~5-15 minutes total\n",
    "- With `MAX_COHORT_SIZE = None`: ~1-2 hours (depending on hardware)\n",
    "\n",
    "**Progress output:**\n",
    "```\n",
    "[1/18] Cohort 2018-11-01: 161,658 customers... done in 45.2s (subsampled from 161,658)\n",
    "[2/18] Cohort 2018-12-01: 98,234 customers... done in 28.1s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models for all cohorts\n",
    "print(f\"Starting model fitting with MAX_COHORT_SIZE = {MAX_COHORT_SIZE}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cohort_results = fit_all_cohorts(\n",
    "    rfm_df=train_rfm_df,\n",
    "    fit_method=\"map\",  # Use MAP for speed\n",
    "    max_cohort_size=MAX_COHORT_SIZE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Fitted {len(cohort_results)} cohort models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of fitted models\n",
    "print(\"\\nFitted Model Summary:\")\n",
    "print(\"-\" * 80)\n",
    "header = (\n",
    "    f\"{'Cohort':<12} {'Customers':>10} {'Repeat':>10} {'Subsampled':>12} {'Time':>8}\"\n",
    ")\n",
    "print(header)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for cohort_id, result in sorted(cohort_results.items()):\n",
    "    sub = \"Yes\" if result[\"was_subsampled\"] else \"No\"\n",
    "    print(\n",
    "        f\"{cohort_id.strftime('%Y-%m'):<12} \"\n",
    "        f\"{result['n_customers']:>10,} \"\n",
    "        f\"{result['n_repeat']:>10,} \"\n",
    "        f\"{sub:>12} \"\n",
    "        f\"{result['fit_time']:>8.1f}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9287426",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Model Diagnostics\n",
    "\n",
    "Let's examine the fitted parameters for a few cohorts to ensure the models\n",
    "converged properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71fee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check BG/NBD parameters for first few cohorts\n",
    "print(\"BG/NBD Model Parameters by Cohort:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for cohort_id in list(cohort_results.keys())[:5]:\n",
    "    result = cohort_results[cohort_id]\n",
    "    bgm = result[\"bgm\"]\n",
    "    print(f\"\\nCohort {cohort_id.strftime('%Y-%m')}:\")\n",
    "    print(bgm.fit_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bcafcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Gamma-Gamma parameters for first few cohorts\n",
    "print(\"Gamma-Gamma Model Parameters by Cohort:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for cohort_id in list(cohort_results.keys())[:5]:\n",
    "    result = cohort_results[cohort_id]\n",
    "    ggm = result[\"ggm\"]\n",
    "    if ggm is not None:\n",
    "        print(f\"\\nCohort {cohort_id.strftime('%Y-%m')}:\")\n",
    "        print(ggm.fit_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5783a748",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Predictions\n",
    "\n",
    "Generate CLV predictions for the test period (approximately 3.5 months = ~105 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83cc505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate future_t in days\n",
    "# Test period: 2020-06-01 to 2020-09-22 (~114 days)\n",
    "future_t_days = (TEST_PERIOD_END - PERIOD_TRAIN_TEST_SPLIT).days\n",
    "print(f\"Forecast horizon: {future_t_days} days ({future_t_days / 30:.1f} months)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5aaef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute aggregated CLV across all cohorts\n",
    "total_clv, clv_by_cohort = aggregate_cohort_clv(\n",
    "    cohort_results=cohort_results,\n",
    "    future_t=future_t_days,\n",
    "    discount_rate=0.0,  # No discounting\n",
    "    time_unit=\"D\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics\n",
    "if total_clv is not None:\n",
    "    total_clv_mean = float(total_clv.mean())\n",
    "    total_clv_values = total_clv.to_numpy().flatten()\n",
    "    total_clv_hdi = az.hdi(total_clv_values, hdi_prob=0.94)\n",
    "\n",
    "    print(f\"\\nTotal Predicted Revenue ({future_t_days} days):\")\n",
    "    print(f\"  Mean: {total_clv_mean:,.2f}\")\n",
    "    print(f\"  94% HDI: [{total_clv_hdi[0]:,.2f}, {total_clv_hdi[1]:,.2f}]\")\n",
    "else:\n",
    "    print(\"No CLV predictions available (check Gamma-Gamma models)\")\n",
    "    total_clv_mean = None\n",
    "    total_clv_hdi = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855ab1e7",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Evaluation\n",
    "\n",
    "Compare predicted revenue with actual revenue from the test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute actual test period revenue\n",
    "actual_monthly_revenue = compute_actual_monthly_revenue(\n",
    "    transactions_df=filtered_df,\n",
    "    start_date=PERIOD_TRAIN_TEST_SPLIT,\n",
    "    end_date=TEST_PERIOD_END,\n",
    ")\n",
    "\n",
    "print(\"Actual Monthly Revenue (Test Period):\")\n",
    "print(actual_monthly_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65793a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total actual revenue\n",
    "actual_total_revenue = actual_monthly_revenue[\"revenue\"].sum()\n",
    "actual_total_customers = actual_monthly_revenue[\"n_customers\"].sum()\n",
    "actual_total_transactions = actual_monthly_revenue[\"n_transactions\"].sum()\n",
    "\n",
    "print(\"\\nActual Test Period Totals:\")\n",
    "print(f\"  Total Revenue: {actual_total_revenue:,.2f}\")\n",
    "print(f\"  Total Customers: {actual_total_customers:,}\")\n",
    "print(f\"  Total Transactions: {actual_total_transactions:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison: Predicted vs Actual\n",
    "if total_clv_mean is not None:\n",
    "    prediction_error = total_clv_mean - actual_total_revenue\n",
    "    prediction_error_pct = (prediction_error / actual_total_revenue) * 100\n",
    "    actual_in_hdi = total_clv_hdi[0] <= actual_total_revenue <= total_clv_hdi[1]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PREDICTION VS ACTUAL COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Predicted Revenue: {total_clv_mean:,.2f}\")\n",
    "    print(f\"94% HDI: [{total_clv_hdi[0]:,.2f}, {total_clv_hdi[1]:,.2f}]\")\n",
    "    print(f\"Actual Revenue: {actual_total_revenue:,.2f}\")\n",
    "    print(f\"Prediction Error: {prediction_error:,.2f} ({prediction_error_pct:+.1f}%)\")\n",
    "    print(f\"Actual within 94% HDI: {actual_in_hdi}\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2affa3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Predicted vs Actual\n",
    "if total_clv_mean is not None:\n",
    "    fig = plot_predicted_vs_actual_revenue(\n",
    "        predicted_total=total_clv_mean,\n",
    "        predicted_hdi=total_clv_hdi,\n",
    "        actual_total=actual_total_revenue,\n",
    "        title=f\"Predicted vs Actual Revenue ({future_t_days}-day Test Period)\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0755777",
   "metadata": {},
   "source": [
    "### Revenue Over Time Plot\n",
    "\n",
    "This visualization shows the posterior predictive revenue distribution over time,\n",
    "with:\n",
    "- **Black line/dots**: Actual revenue\n",
    "- **Orange bands**: Test period predictions (94% and 50% HDI)\n",
    "- **Dashed line**: Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the revenue over time plot\n",
    "# Use DATA_START_DATE for correct cohort assignment (include Oct for cohort computation)\n",
    "fig = plot_revenue_train_test(\n",
    "    transactions_df=filtered_df,\n",
    "    cohort_results=cohort_results,\n",
    "    train_test_split=PERIOD_TRAIN_TEST_SPLIT,\n",
    "    test_end=date(2020, 9, 1),  # Use complete months only\n",
    "    data_start=DATA_START_DATE,  # Include Oct for correct cohort assignment\n",
    "    hdi_probs=(0.5, 0.94),\n",
    "    figsize=(14, 7),\n",
    "    title=\"Total Revenue (Training Cohorts)\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab3693",
   "metadata": {},
   "source": [
    "### Out-of-Sample Revenue Predictions by Cohort\n",
    "\n",
    "Generate faceted plots showing revenue predictions for each cohort.\n",
    "This visualization is similar to the plots in `hm-transactions.ipynb` but\n",
    "uses the CLV (BG/NBD + Gamma-Gamma) model predictions instead of BART.\n",
    "\n",
    "For each cohort we show:\n",
    "- **Blue line/dots**: Training period observed revenue\n",
    "- **Orange band**: Test period 94% HDI prediction interval\n",
    "- **Orange line**: Test period posterior mean prediction\n",
    "- **Orange dots**: Test period observed revenue\n",
    "- **Dashed line**: Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select cohorts to plot (similar to reference notebook)\n",
    "# Indices: [0, 1, 5, 8, 11, 14, 16, 17] filtered by availability\n",
    "all_cohorts = sorted(cohort_results.keys())\n",
    "n_available_cohorts = len(all_cohorts)\n",
    "\n",
    "# Select cohorts to plot (explicit dates to match hm-transactions.ipynb)\n",
    "# These are the same cohorts used in the reference notebook for comparison\n",
    "cohorts_to_plot = [\n",
    "    date(2018, 11, 1),\n",
    "    date(2018, 12, 1),\n",
    "    date(2019, 4, 1),\n",
    "    date(2019, 7, 1),\n",
    "    date(2019, 10, 1),\n",
    "    date(2020, 1, 1),\n",
    "    date(2020, 3, 1),\n",
    "    date(2020, 4, 1),\n",
    "]\n",
    "\n",
    "print(f\"Plotting {len(cohorts_to_plot)} cohorts:\")\n",
    "for c in cohorts_to_plot:\n",
    "    status = \"OK\" if c in cohort_results else \"no model\"\n",
    "    print(f\"  - {c} ({status})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763d712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the faceted revenue predictions plot\n",
    "fig = plot_cohort_revenue_predictions(\n",
    "    cohort_results=cohort_results,\n",
    "    transactions_df=filtered_df,\n",
    "    cohorts_to_plot=cohorts_to_plot,\n",
    "    train_test_split=PERIOD_TRAIN_TEST_SPLIT,\n",
    "    test_end=date(2020, 9, 1),  # Use complete months only\n",
    "    data_start=DATA_START_DATE,  # Include Oct for correct cohort assignment\n",
    "    hdi_prob=0.94,\n",
    "    figsize=(15, 21),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ccde3",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Summary and Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Cohort-Based Approach**: By fitting separate models per cohort, we can\n",
    "   handle the large H&M dataset efficiently.\n",
    "\n",
    "2. **Subsampling**: Using `MAX_COHORT_SIZE` allows for fast testing and\n",
    "   debugging. Set to `None` for full dataset analysis.\n",
    "\n",
    "3. **Model Performance**: Compare the prediction error to evaluate model quality.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. **BG/NBD Assumptions**: The model assumes stationary purchase rates, which\n",
    "   may not hold for seasonal data like fashion retail.\n",
    "\n",
    "2. **Cohort Independence**: We treat cohorts independently, not accounting for\n",
    "   potential cross-cohort effects.\n",
    "\n",
    "3. **Subsampling**: When `MAX_COHORT_SIZE` is set, predictions are for the\n",
    "   subsampled dataset only. For full population predictions, set to `None`.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Compare with the BART-based cohort model from `hm-transactions.ipynb`\n",
    "2. Try MCMC fitting for uncertainty quantification\n",
    "3. Explore cohort-specific seasonality patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COHORT-BASED CLV MODEL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nConfiguration:\")\n",
    "print(f\"  MAX_COHORT_SIZE: {MAX_COHORT_SIZE}\")\n",
    "print(\"  Fit Method: MAP\")\n",
    "print(\"  Time Unit: Days\")\n",
    "\n",
    "print(\"\\nData Summary:\")\n",
    "print(f\"  Cohorts from: {COHORT_START_DATE}\")\n",
    "print(f\"  Training Period: {DATA_START_DATE} to {PERIOD_TRAIN_TEST_SPLIT}\")\n",
    "print(f\"  Test Period: {PERIOD_TRAIN_TEST_SPLIT} to {TEST_PERIOD_END}\")\n",
    "print(f\"  Number of Cohorts: {len(cohort_results)}\")\n",
    "print(f\"  Total Training Customers: {train_rfm_df.height:,}\")\n",
    "\n",
    "print(\"\\nModel Results:\")\n",
    "total_fit_time = sum(r[\"fit_time\"] for r in cohort_results.values())\n",
    "print(f\"  Total Fitting Time: {total_fit_time:.1f}s ({total_fit_time / 60:.1f} min)\")\n",
    "\n",
    "if total_clv_mean is not None:\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(f\"  Forecast Horizon: {future_t_days} days\")\n",
    "    print(f\"  Predicted Revenue: {total_clv_mean:,.2f}\")\n",
    "    print(f\"  Actual Revenue: {actual_total_revenue:,.2f}\")\n",
    "    print(f\"  Prediction Error: {prediction_error_pct:+.1f}%\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
