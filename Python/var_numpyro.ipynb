{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78abff6",
   "metadata": {},
   "source": [
    "# Bayesian Vector Autoregressive Models in Numpyro\n",
    "\n",
    "In this notebook, we present how to implement and fit Bayesian Vector Autoregressive (VAR) models using [NumPyro](https://num.pyro.ai/en/stable/). After fitting the model, we compute the Impulse Response Functions (IRFs) and compare the results with the ones obtained using the statsmodels implementation.\n",
    "\n",
    "https://www.statsmodels.org/stable/vector_ar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1748f78",
   "metadata": {},
   "source": [
    "## Prepare Notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d85db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from jax import random\n",
    "from jaxtyping import Array, Float\n",
    "from numpyro.contrib.control_flow import scan\n",
    "from numpyro.handlers import condition\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.base.datetools import dates_from_str\n",
    "\n",
    "numpyro.set_host_device_count(n=10)\n",
    "\n",
    "rng_key = random.PRNGKey(seed=42)\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jaxtyping\n",
    "%jaxtyping.typechecker beartype.beartype\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bbdd06",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "We are going to use a dataset from the [`statsmodels` package](https://www.statsmodels.org/stable/datasets/index.html). Specifically, we will use the `macrodata` dataset from [Vector Autoregressions tsa.vector_ar](https://www.statsmodels.org/stable/vector_ar.html) tutorial. For the sake of reproducibility, we will keep the exact same code as in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48e3b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> pd.DataFrame:\n",
    "    mdata = sm.datasets.macrodata.load_pandas().data\n",
    "    dates = mdata[[\"year\", \"quarter\"]].astype(int).astype(str)\n",
    "    quarterly = dates[\"year\"] + \"Q\" + dates[\"quarter\"]\n",
    "    quarterly = dates_from_str(quarterly)\n",
    "    mdata = mdata[[\"realgdp\", \"realcons\", \"realinv\"]]\n",
    "    mdata.index = pd.DatetimeIndex(quarterly, freq=\"QE\")\n",
    "    return np.log(mdata).diff().dropna()\n",
    "\n",
    "\n",
    "data: pd.DataFrame = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746662da",
   "metadata": {},
   "source": [
    "## Fit VAR Model with Statsmodels\n",
    "\n",
    "Recall taht a $\\text{VAR}(p)$ model can be written as:\n",
    "\n",
    "$$\n",
    "Y_t = c + \\sum_{j=1}^{p} \\Phi_j Y_{t-j} + \\varepsilon_t,\n",
    "$$\n",
    "\n",
    "where $c$ is a vector of constants, $\\Phi_j$ is the coefficient matrix for the $j$-th lag, and $\\varepsilon_t$ is the error term which is a vector of i.i.d. normal random variables with mean $0$ and covariance matrix $\\Sigma$ . Each matrix $\\Phi_j$ has dimensions $(k, k)$ where $k$ is the number of variables in the model. Let $\\Phi = [\\Phi_1, \\Phi_2, \\ldots, \\Phi_p]$ be the tensor of coefficient matrices of shape $(p, k, k)$ so that we can write the model in vectorized form as:\n",
    "$$\n",
    "Y_t = c + \\Phi \\times \\begin{bmatrix} Y_{t-1} \\\\ Y_{t-2} \\\\ \\vdots \\\\ Y_{t-p} \\end{bmatrix} + \\varepsilon_t,\n",
    "$$\n",
    "\n",
    "Before implementing the model in Numpyro, we fit a VAR model using the `statsmodels` package to get the reference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f65223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Summary of Regression Results   \n",
       "==================================\n",
       "Model:                         VAR\n",
       "Method:                        OLS\n",
       "Date:           Thu, 02, Oct, 2025\n",
       "Time:                     14:54:21\n",
       "--------------------------------------------------------------------\n",
       "No. of Equations:         3.00000    BIC:                   -27.5830\n",
       "Nobs:                     200.000    HQIC:                  -27.7892\n",
       "Log likelihood:           1962.57    FPE:                7.42129e-13\n",
       "AIC:                     -27.9293    Det(Omega_mle):     6.69358e-13\n",
       "--------------------------------------------------------------------\n",
       "Results for equation realgdp\n",
       "==============================================================================\n",
       "                 coefficient       std. error           t-stat            prob\n",
       "------------------------------------------------------------------------------\n",
       "const               0.001527         0.001119            1.365           0.172\n",
       "L1.realgdp         -0.279435         0.169663           -1.647           0.100\n",
       "L1.realcons         0.675016         0.131285            5.142           0.000\n",
       "L1.realinv          0.033219         0.026194            1.268           0.205\n",
       "L2.realgdp          0.008221         0.173522            0.047           0.962\n",
       "L2.realcons         0.290458         0.145904            1.991           0.047\n",
       "L2.realinv         -0.007321         0.025786           -0.284           0.776\n",
       "==============================================================================\n",
       "\n",
       "Results for equation realcons\n",
       "==============================================================================\n",
       "                 coefficient       std. error           t-stat            prob\n",
       "------------------------------------------------------------------------------\n",
       "const               0.005460         0.000969            5.634           0.000\n",
       "L1.realgdp         -0.100468         0.146924           -0.684           0.494\n",
       "L1.realcons         0.268640         0.113690            2.363           0.018\n",
       "L1.realinv          0.025739         0.022683            1.135           0.257\n",
       "L2.realgdp         -0.123174         0.150267           -0.820           0.412\n",
       "L2.realcons         0.232499         0.126350            1.840           0.066\n",
       "L2.realinv          0.023504         0.022330            1.053           0.293\n",
       "==============================================================================\n",
       "\n",
       "Results for equation realinv\n",
       "==============================================================================\n",
       "                 coefficient       std. error           t-stat            prob\n",
       "------------------------------------------------------------------------------\n",
       "const              -0.023903         0.005863           -4.077           0.000\n",
       "L1.realgdp         -1.970974         0.888892           -2.217           0.027\n",
       "L1.realcons         4.414162         0.687825            6.418           0.000\n",
       "L1.realinv          0.225479         0.137234            1.643           0.100\n",
       "L2.realgdp          0.380786         0.909114            0.419           0.675\n",
       "L2.realcons         0.800281         0.764416            1.047           0.295\n",
       "L2.realinv         -0.124079         0.135098           -0.918           0.358\n",
       "==============================================================================\n",
       "\n",
       "Correlation matrix of residuals\n",
       "             realgdp  realcons   realinv\n",
       "realgdp     1.000000  0.603316  0.750722\n",
       "realcons    0.603316  1.000000  0.131951\n",
       "realinv     0.750722  0.131951  1.000000\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_model = VAR(data)\n",
    "\n",
    "var_results = var_model.fit(maxlags=2)\n",
    "\n",
    "var_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4258ea",
   "metadata": {},
   "source": [
    "## NumPyro Implementation\n",
    "\n",
    "Next, we implement the model in Numpyro. The core idea is taken from the NumPyro docs: [Example: VAR(2) process](https://num.pyro.ai/en/stable/examples/var2.html). In our implementation, we make it in such a way that we vectorize the computation over the lags components (i.e. this works for lags larger than $2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9e94c",
   "metadata": {},
   "source": [
    "### Vecorization over Lags\n",
    "\n",
    "The vectorization is a bit tricky at first. So before jumping into the model, we conmsider a simple example. The idea is to vecortize the coeficient matrix $\\Phi$ over the lags $j=1, \\ldots, p$. Let us consider the case of $p=2$ and generate a syntetic matrix $\\Phi$ as we mainly casre about the computation and not the values themselves for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8267c472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8]],\n",
       "\n",
       "       [[ 9, 10, 11],\n",
       "        [12, 13, 14],\n",
       "        [15, 16, 17]]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of variables (taken from the data)\n",
    "n_vars = data.shape[1]\n",
    "# number of lags\n",
    "n_lags = 2\n",
    "\n",
    "# generate a synthetic matrix\n",
    "phi = jnp.arange(n_lags * n_vars * n_vars).reshape(n_lags, n_vars, n_vars)\n",
    "\n",
    "phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80707e21",
   "metadata": {},
   "source": [
    "For the matrix $\\Phi$, the first dimension is the lags, the second dimension is the variables on the rows and the third dimension is the variables on the columns that we want to multiply and sum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b962c68c",
   "metadata": {},
   "source": [
    "Next, we consder a synthetic lags vector which whould represent the lags of the dependent variable $Y_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36572e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[2., 2., 2.],\n",
       "       [2., 2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lags = 2 * jnp.ones((n_lags, n_vars))\n",
    "\n",
    "y_lags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b2e45",
   "metadata": {},
   "source": [
    "The tensor operation we want to perform is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f34c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 66., 102., 138.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise multiplication and sum over the third dimension (columns).\n",
    "(phi * y_lags[..., jnp.newaxis]).sum(axis=(0, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61518d79",
   "metadata": {},
   "source": [
    "This can be achieved by using the [`einsum`](https://docs.jax.dev/en/latest/_autosummary/jax.numpy.einsum.html) function with a proper specification of the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f96233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 66., 102., 138.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.einsum(\"lij,lj->i\", phi, y_lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb437e",
   "metadata": {},
   "source": [
    "We will use the einsum function to perform the operation in the NumPyro model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63930eb8",
   "metadata": {},
   "source": [
    "### NumPyro Model\n",
    "\n",
    "We are now ready to implement the VAR model in NumPyro. The idea is to use the scan function as in the previous example [Notes on an ARMA(1, 1) Model with NumPyro](https://juanitorduz.github.io/arma_numpyro/), see also the [PyData Amsterdam](https://amsterdam2024.pydata.org/cfp/talk/YBTSUV/) video [Time Series forecasting with NumPyro](https://www.youtube.com/watch?v=9Q6r2w0CDB0) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1072803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(\n",
    "    y: Float[Array, \"time vars\"], n_lags: int\n",
    ") -> Float[Array, \"time_minus_n_lags vars\"]:\n",
    "    # Get the number of time steps and variables\n",
    "    n_time, n_vars = y.shape\n",
    "\n",
    "    # --- Priors ---\n",
    "    constant = numpyro.sample(\"constant\", dist.Normal(0, 1).expand([n_vars]))\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(1.0).expand([n_vars]))\n",
    "\n",
    "    l_omega = numpyro.sample(\n",
    "        \"l_omega\", dist.LKJCholesky(dimension=n_vars, concentration=1.0)\n",
    "    )\n",
    "    l_sigma = jnp.einsum(\"...i,...ij->...ij\", sigma, l_omega)\n",
    "\n",
    "    # Sample phi coefficients - shape (n_lags, n_vars, n_vars)\n",
    "    phi = numpyro.sample(\n",
    "        \"phi\", dist.Normal(0, 10).expand([n_lags, n_vars, n_vars]).to_event(3)\n",
    "    )\n",
    "\n",
    "    # --- Transition Function ---\n",
    "\n",
    "    def transition(carry: Array, _) -> tuple[Array, Array]:\n",
    "        # carry: (n_lags, n_vars)\n",
    "        y_lags = carry\n",
    "\n",
    "        # Compute VAR mean\n",
    "        lag_contributions = jnp.einsum(\"lij,lj->i\", phi, y_lags)\n",
    "        m_t = constant + lag_contributions\n",
    "\n",
    "        # Sample observation\n",
    "        y_t = numpyro.sample(\n",
    "            \"y_pred\", dist.MultivariateNormal(loc=m_t, scale_tril=l_sigma)\n",
    "        )\n",
    "\n",
    "        # Update carry: remove oldest, add newest\n",
    "        new_carry = jnp.concatenate([y_lags[1:], y_t[None, :]], axis=0)\n",
    "        return new_carry, y_t\n",
    "\n",
    "    # Initialize and run scan\n",
    "    init_carry = y[:n_lags]\n",
    "    time_indices = jnp.arange(n_lags, n_time)\n",
    "\n",
    "    with condition(data={\"y_pred\": y[n_lags:]}):\n",
    "        _, y_pred = scan(transition, init=init_carry, xs=time_indices)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea410dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.1.2 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"353pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 353.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-112 348.63,-112 348.63,4 -4,4\"/>\n",
       "<!-- constant -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>constant</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"41.63\" cy=\"-90\" rx=\"41.63\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"41.63\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">constant</text>\n",
       "</g>\n",
       "<!-- y_pred -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>y_pred</title>\n",
       "<ellipse fill=\"grey\" stroke=\"black\" cx=\"181.63\" cy=\"-18\" rx=\"36.51\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"181.63\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">y_pred</text>\n",
       "</g>\n",
       "<!-- constant&#45;&gt;y_pred -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>constant&#45;&gt;y_pred</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.96,-75.83C90.18,-64.72 122.17,-48.73 146.55,-36.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"148.09,-39.68 155.47,-32.08 144.96,-33.42 148.09,-39.68\"/>\n",
       "</g>\n",
       "<!-- sigma -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>sigma</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"134.63\" cy=\"-90\" rx=\"33.44\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"134.63\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">sigma</text>\n",
       "</g>\n",
       "<!-- sigma&#45;&gt;y_pred -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>sigma&#45;&gt;y_pred</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M145.53,-72.76C151.08,-64.49 157.97,-54.23 164.24,-44.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"166.95,-47.14 169.62,-36.89 161.14,-43.24 166.95,-47.14\"/>\n",
       "</g>\n",
       "<!-- l_omega -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>l_omega</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"229.63\" cy=\"-90\" rx=\"43.16\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"229.63\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">l_omega</text>\n",
       "</g>\n",
       "<!-- l_omega&#45;&gt;y_pred -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>l_omega&#45;&gt;y_pred</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M218.25,-72.41C212.63,-64.22 205.72,-54.14 199.42,-44.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.32,-42.99 193.78,-36.72 196.55,-46.94 202.32,-42.99\"/>\n",
       "</g>\n",
       "<!-- phi -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>phi</title>\n",
       "<ellipse fill=\"white\" stroke=\"black\" cx=\"317.63\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"317.63\" y=\"-84.95\" font-family=\"Times,serif\" font-size=\"14.00\">phi</text>\n",
       "</g>\n",
       "<!-- phi&#45;&gt;y_pred -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>phi&#45;&gt;y_pred</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M296.68,-78.22C275.2,-67.16 241.43,-49.78 216.03,-36.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"217.89,-33.73 207.4,-32.27 214.69,-39.95 217.89,-33.73\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x3180e04d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y: Float[Array, \"time vars\"] = jnp.array(data)\n",
    "\n",
    "numpyro.render_model(model, model_kwargs={\"y\": y, \"n_lags\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8cd6895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d108fed84600451288cc891aaebf1db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba239c09903f4a21bf5b9052ff7aafc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1f6bfe55f748468da01ffe56b80e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ac3fd3690848c8b434867fa165c7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 893 ms, total: 2min 29s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nuts_kernel = NUTS(model)\n",
    "mcmc = MCMC(\n",
    "    nuts_kernel,\n",
    "    num_warmup=1_000,\n",
    "    num_samples=2_000,\n",
    "    num_chains=4,\n",
    ")\n",
    "\n",
    "# Run inference\n",
    "rng_key, rng_subkey = random.split(rng_key)\n",
    "mcmc.run(rng_subkey, y=y, n_lags=2)\n",
    "\n",
    "# Get samples\n",
    "samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = az.from_numpyro(\n",
    "    mcmc,\n",
    "    coords={\"var_1\": data.columns, \"var_2\": data.columns, \"lag\": range(2, 0, -1)},\n",
    "    dims={\n",
    "        \"constant\": [\"vars\"],\n",
    "        \"sigma\": [\"vars\"],\n",
    "        \"l_omega\": [\"var_1\", \"var_2\"],\n",
    "        \"phi\": [\"lag\", \"var_1\", \"var_2\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b9f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata[\"posterior\"][\"phi\"].mean(dim=[\"chain\", \"draw\"]).sel(var_1=\"realgdp\", lag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b26bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = idata[\"posterior\"][\"l_omega\"].mean(dim=[\"chain\", \"draw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f14e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = a.to_numpy() @ a.to_numpy().T\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a31454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference values from statsmodels VAR(2) results\n",
    "# Simplified construction using list comprehension and f-strings\n",
    "lags = [1, 2]\n",
    "variables = [\"realgdp\", \"realcons\", \"realinv\"]\n",
    "\n",
    "ref_vals_phi = {\n",
    "    \"phi\": [\n",
    "        {\n",
    "            \"lag\": lag,\n",
    "            \"var_1\": var_1,\n",
    "            \"var_2\": var_2,\n",
    "            \"ref_val\": var_results.params[var_1][f\"L{lag}.{var_2}\"],\n",
    "        }\n",
    "        for lag in lags\n",
    "        for var_1 in variables\n",
    "        for var_2 in variables\n",
    "    ]\n",
    "}\n",
    "\n",
    "az.plot_posterior(idata, var_names=[\"phi\"], ref_val=ref_vals_phi, figsize=(18, 20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_irf(\n",
    "    phi: Float[Array, \"n_lags n_vars n_vars\"],\n",
    "    n_steps: int,\n",
    "    shock_size: float = 1.0,\n",
    ") -> Float[Array, \"n_steps n_vars n_vars\"]:\n",
    "    \"\"\"\n",
    "    Compute MA(∞) representation of VAR(p) process (non-orthogonalized IRF).\n",
    "\n",
    "    Implements the statsmodels ma_rep algorithm using jax.lax.scan:\n",
    "    Phi_0 = I\n",
    "    Phi_i = sum_{j=1}^{min(i,p)} Phi_{i-j} @ A_j for i >= 1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    phi : array of shape (n_lags, n_vars, n_vars)\n",
    "        VAR coefficient matrices. phi[j-1] corresponds to A_j.\n",
    "        IMPORTANT: phi[0] must be lag 1 coefficients, phi[1] must be lag 2, etc.\n",
    "        If your coords are reversed (e.g., range(2, 0, -1)), you must reverse\n",
    "        the array before passing it to this function: phi = phi[::-1]\n",
    "    n_steps : int\n",
    "        Number of MA coefficient matrices to compute.\n",
    "    shock_size : float, default=1.0\n",
    "        Scaling factor for identity matrix at t=0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    phis : array of shape (n_steps, n_vars, n_vars)\n",
    "        MA representation. phis[i, :, j] is response of all variables\n",
    "        at time i to a unit shock to variable j at time 0.\n",
    "    \"\"\"\n",
    "    from jax import lax\n",
    "\n",
    "    n_lags, n_vars, _ = phi.shape\n",
    "\n",
    "    def scan_fn(carry, i):\n",
    "        \"\"\"\n",
    "        Compute Phi_i from previous MA matrices.\n",
    "\n",
    "        carry: Array of shape (n_lags, n_vars, n_vars) containing the last n_lags MA matrices\n",
    "               carry[0] is Phi_{i-1}, carry[1] is Phi_{i-2}, ..., carry[n_lags-1] is Phi_{i-n_lags}\n",
    "        i: current time step\n",
    "        \"\"\"\n",
    "        # Compute Phi_i = sum_{j=1}^{min(i,p)} Phi_{i-j} @ A_j\n",
    "        # We need to handle the case where i < n_lags (early steps)\n",
    "\n",
    "        # carry[0] is Phi_{i-1}, carry[1] is Phi_{i-2}, etc.\n",
    "        # phi[0] is A_1 (lag 1), phi[1] is A_2 (lag 2), etc.\n",
    "\n",
    "        # For each lag j from 1 to min(i, n_lags):\n",
    "        #   Phi_{i-j} is carry[j-1]\n",
    "        #   A_j is phi[j-1]\n",
    "\n",
    "        # Create a mask to only sum over valid lags (up to min(i, n_lags))\n",
    "        valid_lags = jnp.arange(n_lags) < jnp.minimum(i, n_lags)\n",
    "\n",
    "        # Compute contributions: Phi_{i-j} @ A_j for each j\n",
    "        # carry[j] @ phi[j] for j in range(n_lags)\n",
    "        contributions = jnp.einsum(\"jkl,jlm->jkm\", carry, phi)\n",
    "\n",
    "        # Mask invalid contributions and sum\n",
    "        phi_i = jnp.sum(contributions * valid_lags[:, None, None], axis=0)\n",
    "\n",
    "        # Update carry: shift everything by 1 and add new phi_i at the front\n",
    "        new_carry = jnp.concatenate([phi_i[None, :, :], carry[:-1]], axis=0)\n",
    "\n",
    "        return new_carry, phi_i\n",
    "\n",
    "    # Initialize carry with zeros and set Phi_0 = I at the front\n",
    "    phi_0 = shock_size * jnp.eye(n_vars)\n",
    "    init_carry = jnp.concatenate(\n",
    "        [phi_0[None, :, :], jnp.zeros((n_lags - 1, n_vars, n_vars))], axis=0\n",
    "    )\n",
    "\n",
    "    # Run scan for steps 1 to n_steps-1\n",
    "    if n_steps == 1:\n",
    "        return phi_0[None, :, :]\n",
    "\n",
    "    time_steps = jnp.arange(1, n_steps)\n",
    "    _, phis_rest = lax.scan(scan_fn, init_carry, time_steps)\n",
    "\n",
    "    # Concatenate Phi_0 with the rest\n",
    "    phis = jnp.concatenate([phi_0[None, :, :], phis_rest], axis=0)\n",
    "\n",
    "    return phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ec8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the new scan-based implementation matches statsmodels\n",
    "# Using the exact statsmodels coefficients\n",
    "phi_sm = jnp.array(var_results.coefs)\n",
    "n_test_steps = 10\n",
    "\n",
    "# Compute IRF with scan-based function\n",
    "irf_jax_scan = compute_irf(phi_sm, n_steps=n_test_steps)\n",
    "\n",
    "# Get statsmodels IRF (ma_rep)\n",
    "irf_sm = var_results.ma_rep(maxn=n_test_steps - 1)\n",
    "\n",
    "# Compare\n",
    "max_diff = jnp.max(jnp.abs(irf_jax_scan - irf_sm))\n",
    "print(f\"Maximum absolute difference between JAX (scan) and statsmodels: {max_diff:.2e}\")\n",
    "\n",
    "if max_diff < 1e-6:\n",
    "    print(\"✓ Scan-based implementation matches statsmodels perfectly!\")\n",
    "else:\n",
    "    print(\"✗ Differences detected\")\n",
    "    print(f\"\\nIRF at t=0 difference:\\n{jnp.abs(irf_jax_scan[0] - irf_sm[0])}\")\n",
    "    print(f\"\\nIRF at t=1 difference:\\n{jnp.abs(irf_jax_scan[1] - irf_sm[1])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb680cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark: Compare JIT-compiled vs non-JIT performance\n",
    "from jax import jit\n",
    "import time\n",
    "\n",
    "# JIT-compile the function\n",
    "# Note: n_steps is a static argument (compile-time constant)\n",
    "compute_irf_jit = jit(compute_irf, static_argnames=[\"n_steps\"])\n",
    "\n",
    "# Warm-up: First call includes compilation time\n",
    "print(\"Warming up JIT compilation...\")\n",
    "_ = compute_irf_jit(phi_sm, n_steps=10)\n",
    "print(\"✓ JIT compilation complete!\\n\")\n",
    "\n",
    "# Benchmark with a larger number of steps\n",
    "n_benchmark_steps = 50\n",
    "n_runs = 100\n",
    "\n",
    "# Non-JIT version\n",
    "print(\"Benchmarking non-JIT version...\")\n",
    "start = time.time()\n",
    "for _ in range(n_runs):\n",
    "    _ = compute_irf(phi_sm, n_steps=n_benchmark_steps)\n",
    "time_no_jit = (time.time() - start) / n_runs\n",
    "\n",
    "# JIT version\n",
    "print(\"Benchmarking JIT version...\")\n",
    "start = time.time()\n",
    "for _ in range(n_runs):\n",
    "    _ = compute_irf_jit(phi_sm, n_steps=n_benchmark_steps)\n",
    "    _.block_until_ready()  # Wait for GPU/TPU computation to finish\n",
    "time_jit = (time.time() - start) / n_runs\n",
    "\n",
    "# Results\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"PERFORMANCE COMPARISON ({n_benchmark_steps} IRF steps)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"Non-JIT version: {time_no_jit * 1000:.3f} ms per call\")\n",
    "print(f\"JIT version:     {time_jit * 1000:.3f} ms per call\")\n",
    "print(f\"Speedup:         {time_no_jit / time_jit:.1f}x faster with JIT\")\n",
    "print(f\"\\n✓ Use compute_irf_jit for production code!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ADVANTAGES OF SCAN + JIT:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"  1. Significant speedup (typically 10-50x faster)\")\n",
    "print(\"  2. Memory efficient (no intermediate array storage)\")\n",
    "print(\"  3. Better for automatic differentiation if needed\")\n",
    "print(\"  4. Can be vmapped over multiple posterior samples\")\n",
    "print(\"  5. Idiomatic JAX code\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda0d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced: Compute IRFs for ALL posterior samples using vmap\n",
    "# This is useful for uncertainty quantification\n",
    "from jax import vmap\n",
    "\n",
    "# Get all posterior samples (flatten chain and draw dimensions)\n",
    "phi_samples = idata[\"posterior\"][\"phi\"].stack(sample=[\"chain\", \"draw\"]).values\n",
    "# Reverse lag order for all samples\n",
    "phi_samples = phi_samples[::-1, :, :, :]  # Shape: (n_lags, n_vars, n_vars, n_samples)\n",
    "\n",
    "# Transpose to get samples as first dimension\n",
    "phi_samples = jnp.transpose(\n",
    "    phi_samples, (3, 0, 1, 2)\n",
    ")  # Shape: (n_samples, n_lags, n_vars, n_vars)\n",
    "\n",
    "print(f\"Phi samples shape: {phi_samples.shape}\")\n",
    "print(f\"Number of posterior samples: {phi_samples.shape[0]}\")\n",
    "\n",
    "# Create a vmapped version that computes IRF for each posterior sample\n",
    "# vmap over the first axis (samples)\n",
    "compute_irf_vmap = vmap(compute_irf_jit, in_axes=(0, None, None))\n",
    "\n",
    "# Compute IRFs for all samples at once!\n",
    "print(f\"\\nComputing IRFs for all {phi_samples.shape[0]} posterior samples...\")\n",
    "n_irf_steps = 10\n",
    "irf_samples = compute_irf_vmap(phi_samples, n_irf_steps, 1.0)\n",
    "\n",
    "print(f\"IRF samples shape: {irf_samples.shape}\")\n",
    "print(\n",
    "    f\"Shape: (n_samples={irf_samples.shape[0]}, n_steps={irf_samples.shape[1]}, n_vars={irf_samples.shape[2]}, n_vars={irf_samples.shape[3]})\"\n",
    ")\n",
    "\n",
    "# Compute credible intervals\n",
    "irf_mean_vmap = irf_samples.mean(axis=0)\n",
    "irf_lower = jnp.percentile(irf_samples, 5, axis=0)\n",
    "irf_upper = jnp.percentile(irf_samples, 95, axis=0)\n",
    "\n",
    "print(f\"\\n✓ Successfully computed IRFs with uncertainty bands!\")\n",
    "print(f\"\\nYou can now plot IRFs with credible intervals:\")\n",
    "print(f\"  - irf_mean_vmap: posterior mean IRF\")\n",
    "print(f\"  - irf_lower: 5th percentile\")\n",
    "print(f\"  - irf_upper: 95th percentile\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8685103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0715c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test IRF computation with posterior mean\n",
    "phi_mean = idata[\"posterior\"][\"phi\"].mean(dim=[\"chain\", \"draw\"]).values\n",
    "l_omega_mean = idata[\"posterior\"][\"l_omega\"].mean(dim=[\"chain\", \"draw\"]).values\n",
    "sigma_mean = idata[\"posterior\"][\"sigma\"].mean(dim=[\"chain\", \"draw\"]).values\n",
    "\n",
    "# IMPORTANT: Reverse lag order! The coords were defined as range(2, 0, -1) which is [2, 1]\n",
    "# So phi_mean[0] is lag 2 and phi_mean[1] is lag 1, but compute_irf expects\n",
    "# phi[0] = lag 1, phi[1] = lag 2\n",
    "phi_mean = phi_mean[::-1]  # Reverse the lag dimension\n",
    "\n",
    "# Construct the Cholesky factor\n",
    "l_sigma_mean = sigma_mean[:, None] * l_omega_mean\n",
    "\n",
    "# Compute IRF for 10 steps\n",
    "n_irf_steps = 10\n",
    "irf_mean = compute_irf(phi_mean, n_steps=n_irf_steps)\n",
    "\n",
    "print(f\"IRF shape: {irf_mean.shape}\")\n",
    "print(f\"IRF at t=0 (initial shock):\\n{irf_mean[0]}\")\n",
    "print(f\"\\nIRF at t=1:\\n{irf_mean[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with statsmodels IRF\n",
    "var_irf = var_results.irf(n_irf_steps)\n",
    "\n",
    "# Plot comparison for a specific shock -> response pair\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "shock_var = \"realgdp\"\n",
    "response_vars = [\"realgdp\", \"realcons\", \"realinv\"]\n",
    "shock_idx = list(data.columns).index(shock_var)\n",
    "\n",
    "for i, response_var in enumerate(response_vars):\n",
    "    response_idx = list(data.columns).index(response_var)\n",
    "\n",
    "    # Statsmodels IRF\n",
    "    sm_irf = var_irf.irfs[:, response_idx, shock_idx]\n",
    "\n",
    "    # Our JAX IRF (posterior mean)\n",
    "    jax_irf = irf_mean[:, response_idx, shock_idx]\n",
    "\n",
    "    axes[i].plot(sm_irf, label=\"Statsmodels\", marker=\"o\", alpha=0.7)\n",
    "    axes[i].plot(jax_irf, label=\"JAX (posterior mean)\", marker=\"s\", alpha=0.7)\n",
    "    axes[i].axhline(0, color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
    "    axes[i].set_title(f\"Response of {response_var} to {shock_var} shock\")\n",
    "    axes[i].set_xlabel(\"Periods\")\n",
    "    axes[i].set_ylabel(\"Response\")\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99cd0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47adf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
