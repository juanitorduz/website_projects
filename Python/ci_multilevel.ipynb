{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f116994d",
   "metadata": {},
   "source": [
    "# Causal Inference with Multilevel Models: The Electric Company Example\n",
    "\n",
    "Estimating causal effects from clustered or grouped data requires careful attention to the hierarchical structure of observations. When units are nested within groups—such as students within classrooms, or patients within hospitals—ignoring this structure can lead to incorrect standard errors, inefficient estimates, and invalid causal inferences. Multilevel models provide a principled framework for handling such data while leveraging the advantages of partial pooling across groups.\n",
    "\n",
    "This notebook reproduces and extends the analysis from **Chapter 23** of Gelman and Hill's *\"Data Analysis Using Regression and Multilevel/Hierarchical Models\"* (page 529). We demonstrate two complementary approaches to modeling treatment effects in hierarchical data: first, a model with varying intercepts that efficiently controls for group-level confounding, and second, a more flexible covariance model that allows treatment effects themselves to vary across groups. Together, these models illustrate how multilevel structures enhance both the efficiency and interpretability of causal effect estimation.\n",
    "\n",
    "## Context\n",
    "\n",
    "In the 1970s, an educational television show called **\"The Electric Company\"** was produced to help children learn to read. A randomized experiment was conducted to estimate the causal effect of watching the show on reading test scores. This study provides an excellent setting for demonstrating multilevel modeling techniques in causal inference, as the experimental design naturally produces clustered data.\n",
    "\n",
    "## Study Design\n",
    "\n",
    "The experiment employed a **paired randomized design** across schools and grades:\n",
    "-   **Pairs**: Classrooms were matched into pairs within the same school and grade (e.g., two 1st grade classes in the same school).\n",
    "-   **Treatment**: Within each pair, one classroom was randomly assigned to the **treatment group** (watched the show regularly) and the other to the **control group** (did not watch).\n",
    "-   **Outcome**: Reading test scores at the end of the academic year (`post_test`), with adjustment for pre-test scores (`pre_test`) to increase precision.\n",
    "\n",
    "This **paired randomized design** is powerful because randomization within pairs ensures that treatment assignment is independent of pair-level confounders such as school quality, neighborhood characteristics, and baseline achievement levels. However, the data structure is inherently **clustered**: observations within the same pair are not independent. This clustering motivates the use of multilevel models to correctly account for within-pair correlation and to efficiently estimate both average treatment effects and the heterogeneity of effects across pairs.\n",
    "\n",
    "## Roadmap\n",
    "\n",
    "We proceed in two parts:\n",
    "-   **Part 1**: We estimate a **Hierarchical Intercept Model** where pair-specific intercepts account for baseline differences across groups while assuming a common treatment effect.\n",
    "-   **Part 2**: We extend to a **Covariance Model** that allows both intercepts and treatment effects to vary across pairs, capturing treatment effect heterogeneity and estimating the correlation between baseline performance and treatment response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb35697",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Hierarchical Intercept Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ad863",
   "metadata": {},
   "source": [
    "### Prepare Notebook\n",
    "\n",
    "We begin by importing the necessary libraries for Bayesian modeling (PyMC), visualization (ArViz, Matplotlib), data manipulation (Polars), and preprocessing (scikit-learn). The notebook uses NumPyro as the NUTS sampler backend for efficient posterior inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be65f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import preliz as pz\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt\n",
    "from marginaleffects import datagrid\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 6]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fcb6e9",
   "metadata": {},
   "source": [
    "### Read Data\n",
    "\n",
    "We load the Electric Company dataset from the ROS-Examples repository. The data contains pre-test and post-test reading scores for students in paired classrooms across four grade levels. Each pair consists of one treatment and one control classroom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5575f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/ElectricCompany/data/electric.csv\"\n",
    "raw_df = pl.read_csv(data_path).drop([\"supp\", \"\"]).sort([\"grade\", \"pair_id\"])\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0238c199",
   "metadata": {},
   "source": [
    "The dataset includes: `grade` (grade level), `pair_id` (identifier for matched classroom pairs), `treatment` (binary indicator), `pre_test` (baseline reading score), and `post_test` (outcome reading score).\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "Before modeling, it is essential to understand the structure and variability in the data. Since the design relies on paired classrooms, we should inspect the distribution of test scores across grades and pairs to identify the sources of variation that our multilevel model must capture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a5c04",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "We standardize the numeric variables (test scores) to facilitate prior specification and improve sampling efficiency. Grade and pair identifiers are encoded as integers for use as group indices in the hierarchical model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a2b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"pre_test\", \"post_test\"]\n",
    "ordinal_features = [\"grade\", \"pair_id\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"ord\", OrdinalEncoder(dtype=int), ordinal_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ").set_output(transform=\"polars\")\n",
    "\n",
    "\n",
    "df = preprocessor.fit_transform(raw_df)\n",
    "df.columns = [col.split(\"__\")[-1] for col in df.columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca45ee",
   "metadata": {},
   "source": [
    "We extract the covariate matrix containing only the pre-test scores, which will be used to control for baseline differences when estimating the treatment effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [\"pre_test\"]\n",
    "x_df = df[x_columns]\n",
    "\n",
    "x_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e7afd",
   "metadata": {},
   "source": [
    "Next, we set up the coordinate system for our PyMC model. This includes dimensions for covariates, grades, pairs, and observations, which will allow us to structure the hierarchical relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc8ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grades = len(preprocessor[\"ord\"].categories_[ordinal_features.index(\"grade\")])\n",
    "n_pairs = len(preprocessor[\"ord\"].categories_[ordinal_features.index(\"pair_id\")])\n",
    "\n",
    "coords = {\n",
    "    # covariates\n",
    "    \"covariates\": x_df.columns,\n",
    "    # grade\n",
    "    \"grade\": preprocessor[\"ord\"].categories_[ordinal_features.index(\"grade\")],\n",
    "    # object categories (groups)\n",
    "    \"pair_id\": preprocessor[\"ord\"].categories_[ordinal_features.index(\"pair_id\")],\n",
    "    # index\n",
    "    \"obs_idx\": np.arange(len(df)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa5d79",
   "metadata": {},
   "source": [
    "### Model Specification\n",
    "\n",
    "#### Motivation: Why Multilevel?\n",
    "\n",
    "The data is **clustered** into pairs of classrooms. Observations within the same pair (same school/grade) are likely correlated due to shared unobserved factors like school quality, neighborhood demographics, or teacher characteristics. Ignoring this structure would violate the independence assumption of standard regression.\n",
    "\n",
    "To estimate the causal effect, we have two main strategies to handle this clustering:\n",
    "\n",
    "#### Alternative 1: Fixed Effects (FE)\n",
    "\n",
    "We could include a **dummy variable (intercept) for every pair**.\n",
    "-   **Pros**: This controls for **ALL** time-invariant pair-level unobserved confounders. It effectively \"closes back doors\" related to the school or neighborhood (see *The Effect*, Chapter 16).\n",
    "-   **Cons**: It consumes a massive number of degrees of freedom ($N/2$ parameters just for intercepts!). With many small groups (pairs), this can lead to noisy and inefficient estimates.\n",
    "\n",
    "#### Alternative 2: Random Effects (RE) / Hierarchical Intercepts\n",
    "\n",
    "We model the pair intercepts as coming from a common distribution, e.g., $\\alpha_{j} \\sim N(\\mu, \\sigma)$.\n",
    "-   **Pros**: This uses **partial pooling**. The model learns the variance $\\sigma$ and \"shrinks\" noisy pair estimates toward the global mean. It is far more efficient than FE.\n",
    "\n",
    "##### Addressing Random Effects: A Note of Caution\n",
    "\n",
    "A fundamental concern with Random Effects models, discussed extensively in econometrics and causal inference, is the assumption that group effects are **uncorrelated** with the predictors ($Cov(\\alpha_j, X) = 0$). When this assumption is violated—for example, if high-performing schools both score higher at baseline and implement treatments differently—standard Random Effects estimates can be biased. Fixed Effects models avoid this problem by differencing out all time-invariant group characteristics, making no assumptions about their correlation with predictors. This is why Fixed Effects are often preferred in observational studies where such correlations are likely (Huntington-Klein, 2021, *The Effect*, Chapter 16).\n",
    "\n",
    "**Why Random Effects are Valid in this Randomized Design:**\n",
    "\n",
    "However, the concern about correlation between group effects and predictors does not apply uniformly to all variables. Crucially, in this experiment, **treatment was randomized WITHIN pairs**.\n",
    "-   Because of randomization, the treatment assignment is **uncorrelated** with the pair's baseline characteristics (the \"random effect\") by design.\n",
    "-   The randomization mechanism ensures $Cov(\\alpha_j, T_i) = 0$ for the treatment variable, even if $Cov(\\alpha_j, X_i) \\neq 0$ for other covariates.\n",
    "-   Therefore, the standard critique of Random Effects does not threaten the validity of our causal effect estimate for treatment, though we may still need to control for other confounders like pre-test scores.\n",
    "\n",
    "We can thus use a **Hierarchical Intercept Model** to efficiently control for pair-level heterogeneity and obtain correct standard errors without the heavy penalty of Fixed Effects.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{post\\_test}_i &\\sim N(\\mu_i, \\sigma_y) \\\\\n",
    "\\mu_i &= \\alpha_{\\text{pair}[i]} + \\beta_T \\cdot T_i + \\beta_x \\cdot \\text{pre\\_test}_i \\\\\n",
    "\\alpha_j &\\sim N(\\mu_\\alpha, \\sigma_\\alpha)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here, $i$ indexes observations, $j$ indexes pairs, $T_i$ is the treatment indicator, and $\\alpha_j$ are the pair-specific intercepts. The hierarchical structure on $\\alpha_j$ implements partial pooling: pairs with little data are shrunk toward the grade-level mean $\\mu_\\alpha$, while pairs with more data are allowed to deviate. We implement this using a non-centered parametrization for improved sampling efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e833c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model(coords=coords) as model:\n",
    "    # --- Data Containers ---\n",
    "    # covariates\n",
    "    x_data = pm.Data(\"x_data\", x_df, dims=(\"obs_idx\", \"covariates\"))\n",
    "    # grade\n",
    "    grade_idx_data = pm.Data(\"grade_idx_data\", df[\"grade\"].to_numpy(), dims=\"obs_idx\")\n",
    "    # object categories\n",
    "    pair_idx_data = pm.Data(\"pair_idx_data\", df[\"pair_id\"].to_numpy(), dims=\"obs_idx\")\n",
    "    # treatment\n",
    "    treatment_data = pm.Data(\n",
    "        \"treatment_data\", df[\"treatment\"].to_numpy(), dims=(\"obs_idx\")\n",
    "    )\n",
    "    # outcome\n",
    "    post_test_data = pm.Data(\n",
    "        \"post_test_data\", df[\"post_test\"].to_numpy(), dims=\"obs_idx\"\n",
    "    )\n",
    "\n",
    "    # --- Priors ---\n",
    "    mu_alpha = pm.Normal(\"mu_alpha\", mu=0, sigma=1, dims=(\"grade\"))\n",
    "    sigma_alpha = pm.HalfNormal(\"sigma_alpha\", sigma=1, dims=(\"grade\"))\n",
    "    z_alpha = pm.Normal(\"z_alpha\", mu=0, sigma=1, dims=(\"pair_id\", \"grade\"))\n",
    "\n",
    "    beta_treatment = pm.Normal(\"beta_treatment\", mu=0, sigma=1, dims=(\"grade\"))\n",
    "    beta_x = pm.Normal(\"beta_x\", mu=0, sigma=1, dims=(\"grade\", \"covariates\"))\n",
    "\n",
    "    sigma_outcome = pm.HalfNormal(\"sigma_outcome\", sigma=1, dims=(\"grade\"))\n",
    "\n",
    "    # --- Parametrization ---\n",
    "    # Non-centered parametrization for the random intercepts\n",
    "    alpha = pm.Deterministic(\n",
    "        \"alpha\", mu_alpha + z_alpha * sigma_alpha, dims=(\"pair_id\", \"grade\")\n",
    "    )\n",
    "\n",
    "    mu_outcome = pm.Deterministic(\n",
    "        \"mu_outcome\",\n",
    "        alpha[pair_idx_data, grade_idx_data]\n",
    "        + beta_treatment[grade_idx_data] * treatment_data\n",
    "        + (beta_x[grade_idx_data] * x_data).sum(axis=-1),\n",
    "        dims=(\"obs_idx\"),\n",
    "    )\n",
    "\n",
    "    # --- Likelihood ---\n",
    "    pm.Normal(\n",
    "        \"post_test_obs\",\n",
    "        mu=mu_outcome,\n",
    "        sigma=sigma_outcome[grade_idx_data],\n",
    "        observed=post_test_data,\n",
    "        dims=\"obs_idx\",\n",
    "    )\n",
    "\n",
    "\n",
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c925a4eb",
   "metadata": {},
   "source": [
    "The graphical representation above shows the dependency structure of our model: how the observed data (`post_test_obs`) depends on the hierarchical parameters through the mean structure (`mu_outcome`).\n",
    "\n",
    "### Prior Predictive Check\n",
    "\n",
    "Before fitting the model to data, we simulate from the prior distribution to ensure our priors are reasonable and produce plausible outcomes. This step helps detect specification errors and poorly calibrated priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c62acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    idata = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "az.plot_ppc(idata, group=\"prior\", ax=ax)\n",
    "az.plot_dist(df[\"post_test\"].to_numpy(), color=\"black\", ax=ax)\n",
    "ax.set_title(\"Prior Predictive Check\", fontsize=18, fontweight=\"bold\", y=1.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db502b",
   "metadata": {},
   "source": [
    "The prior predictive distribution (blue) is compared against the observed data (black). The priors allow for a wide range of plausible outcomes, which is appropriate given our standardized data. The overlap indicates that the observed data are not surprising under our prior assumptions.\n",
    "\n",
    "### Posterior Inference\n",
    "\n",
    "We now fit the model using Hamiltonian Monte Carlo (HMC) via the NumPyro backend. We run 4 chains with 1,500 tuning iterations and 1,000 post-warmup draws per chain, using a high target acceptance rate (0.9) to ensure thorough exploration of the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    idata.extend(\n",
    "        pm.sample(\n",
    "            tune=1_500,\n",
    "            draws=1_000,\n",
    "            target_accept=0.9,\n",
    "            chains=4,\n",
    "            nuts_sampler=\"numpyro\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    idata.extend(pm.sample_posterior_predictive(idata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e9a92",
   "metadata": {},
   "source": [
    "After sampling, we generate posterior predictive samples to assess model fit. These predictions will be used to evaluate how well the model captures the observed data patterns.\n",
    "\n",
    "### Model Diagnostics\n",
    "\n",
    "We check for sampling pathologies that would indicate problems with the posterior geometry or sampler configuration. The primary diagnostic is the number of divergent transitions, which should ideally be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata[\"sample_stats\"][\"diverging\"].sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e04f53",
   "metadata": {},
   "source": [
    "No divergent transitions indicate that the sampler successfully explored the posterior without encountering problematic curvature. We also examine the summary statistics and trace plots to assess convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754eca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(\n",
    "    idata,\n",
    "    var_names=[\n",
    "        \"beta_treatment\",\n",
    "        \"beta_x\",\n",
    "        \"mu_alpha\",\n",
    "        \"sigma_alpha\",\n",
    "        \"sigma_outcome\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe862a2",
   "metadata": {},
   "source": [
    "The summary statistics show effective sample sizes (ESS) and $\\hat{R}$ diagnostics for key parameters. Values of $\\hat{R} \\approx 1$ indicate convergence across chains. The treatment effect parameter (`beta_treatment`) and variance components are of primary interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44006ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = az.plot_trace(\n",
    "    idata,\n",
    "    var_names=[\n",
    "        \"beta_treatment\",\n",
    "        \"beta_x\",\n",
    "        \"mu_alpha\",\n",
    "        \"sigma_alpha\",\n",
    "        \"sigma_outcome\",\n",
    "    ],\n",
    "    figsize=(10, 8),\n",
    ")\n",
    "\n",
    "\n",
    "plt.gcf().suptitle(\"Model Trace\", fontsize=18, fontweight=\"bold\", y=1.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19f02e",
   "metadata": {},
   "source": [
    "The trace plots show good mixing across chains (overlapping colors) and stable posterior distributions (smooth histograms on the left). The chains have converged to stationary distributions, confirming the reliability of our posterior estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "az.plot_ppc(idata, group=\"posterior\", num_pp_samples=500, ax=ax)\n",
    "ax.set_title(\"Posterior Predictive Check\", fontsize=18, fontweight=\"bold\", y=1.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5201dbb8",
   "metadata": {},
   "source": [
    "The posterior predictive distribution closely matches the observed data, indicating that the model captures the essential features of the data-generating process. This gives us confidence in using the model for causal inference.\n",
    "\n",
    "### Treatment Effect Estimates\n",
    "\n",
    "We now examine the estimated treatment effects. The parameter `beta_treatment` represents the average causal effect of watching \"The Electric Company\" on standardized test scores, estimated separately for each grade level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a0d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(idata, combined=True, var_names=[\"beta_treatment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac0fc8",
   "metadata": {},
   "source": [
    "The forest plot shows the posterior distributions of treatment effects for each grade. The point estimates and credible intervals provide evidence about the magnitude and uncertainty of the causal effect. To interpret these effects in the original scale, we transform them back from standardized units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(\n",
    "    idata[\"posterior\"][\"beta_treatment\"]\n",
    "    * preprocessor[\"num\"].scale_[numeric_features.index(\"post_test\")],\n",
    "    combined=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d086a6",
   "metadata": {},
   "source": [
    "These are the treatment effects expressed in the original units of the test scores. Positive values indicate that the treatment group (who watched the show) scored higher on average than the control group.\n",
    "\n",
    "### Counterfactual Prediction Grids\n",
    "\n",
    "To compute the average treatment effect (ATE) more explicitly, we construct prediction grids that span the range of pre-test scores for both treatment and control conditions. This allows us to compute counterfactual predictions: what would have happened to the same students under both treatment and control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df_control_grid = datagrid(\n",
    "    newdata=raw_df,\n",
    "    treatment=0,\n",
    "    grade=preprocessor[\"ord\"].categories_[ordinal_features.index(\"grade\")],\n",
    "    pair_id=preprocessor[\"ord\"].categories_[ordinal_features.index(\"pair_id\")],\n",
    "    pre_test=np.linspace(raw_df[\"pre_test\"].min(), raw_df[\"pre_test\"].max(), 10),\n",
    ")\n",
    "\n",
    "df_control_grid = preprocessor.transform(raw_df_control_grid)\n",
    "df_control_grid.columns = [col.split(\"__\")[-1] for col in df_control_grid.columns]\n",
    "x_df_control_grid = df_control_grid[x_columns]\n",
    "\n",
    "raw_df_treatment_grid = datagrid(\n",
    "    newdata=raw_df,\n",
    "    treatment=1,\n",
    "    grade=preprocessor[\"ord\"].categories_[ordinal_features.index(\"grade\")],\n",
    "    pair_id=preprocessor[\"ord\"].categories_[ordinal_features.index(\"pair_id\")],\n",
    "    pre_test=np.linspace(raw_df[\"pre_test\"].min(), raw_df[\"pre_test\"].max(), 10),\n",
    ")\n",
    "\n",
    "df_treatment_grid = preprocessor.transform(raw_df_treatment_grid)\n",
    "df_treatment_grid.columns = [col.split(\"__\")[-1] for col in df_treatment_grid.columns]\n",
    "x_df_treatment_grid = df_treatment_grid[x_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd192a",
   "metadata": {},
   "source": [
    "We have created two grids: one with treatment set to 0 (control) and one with treatment set to 1 (treated), both spanning the observed range of pre-test scores and all grade-pair combinations.\n",
    "\n",
    "### Counterfactual Estimates\n",
    "\n",
    "We now generate posterior predictive samples under each counterfactual scenario. For the control grid, we predict outcomes as if all students were in the control condition. For the treatment grid, we predict outcomes as if all students watched the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acaf685",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pm.set_data(\n",
    "        new_data={\n",
    "            \"x_data\": x_df_control_grid,\n",
    "            \"grade_idx_data\": df_control_grid[\"grade\"].to_numpy(),\n",
    "            \"pair_idx_data\": df_control_grid[\"pair_id\"].to_numpy(),\n",
    "            \"treatment_data\": df_control_grid[\"treatment\"].to_numpy(),\n",
    "            \"post_test_data\": df_control_grid[\"post_test\"].to_numpy(),\n",
    "        },\n",
    "        coords={\n",
    "            \"covariates\": x_df_control_grid.columns,\n",
    "            \"grade\": preprocessor[\"ord\"].categories_[ordinal_features.index(\"grade\")],\n",
    "            \"pair_id\": preprocessor[\"ord\"].categories_[\n",
    "                ordinal_features.index(\"pair_id\")\n",
    "            ],\n",
    "            \"obs_idx\": np.arange(len(df_control_grid)),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    posterior_predictive_control = pm.sample_posterior_predictive(\n",
    "        idata, var_names=[\"post_test_obs\", \"mu_outcome\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4c839",
   "metadata": {},
   "source": [
    "The control counterfactual predictions represent the expected outcomes in the absence of treatment, conditioning on the observed covariates and the estimated model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3049607",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    pm.set_data(\n",
    "        new_data={\n",
    "            \"x_data\": x_df_treatment_grid,\n",
    "            \"grade_idx_data\": df_treatment_grid[\"grade\"].to_numpy(),\n",
    "            \"pair_idx_data\": df_treatment_grid[\"pair_id\"].to_numpy(),\n",
    "            \"treatment_data\": df_treatment_grid[\"treatment\"].to_numpy(),\n",
    "            \"post_test_data\": df_treatment_grid[\"post_test\"].to_numpy(),\n",
    "        },\n",
    "        coords={\n",
    "            \"covariates\": x_df_treatment_grid.columns,\n",
    "            \"grade\": preprocessor[\"ord\"].categories_[ordinal_features.index(\"grade\")],\n",
    "            \"pair_id\": preprocessor[\"ord\"].categories_[\n",
    "                ordinal_features.index(\"pair_id\")\n",
    "            ],\n",
    "            \"obs_idx\": np.arange(len(df_treatment_grid)),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    posterior_predictive_treatment = pm.sample_posterior_predictive(\n",
    "        idata, var_names=[\"post_test_obs\", \"mu_outcome\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada58ec3",
   "metadata": {},
   "source": [
    "Similarly, the treatment counterfactual predictions represent expected outcomes if all students had watched the show. The difference between these two counterfactuals yields the causal effect.\n",
    "\n",
    "### Results: Treatment Effect Estimates\n",
    "\n",
    "We can now compute the **average treatment effect (ATE)** by comparing the posterior predictive distributions under the counterfactual scenarios (Treatment vs. Control). The difference between these predictions, averaged across all observations in the grid, provides a distribution for the causal effect.\n",
    "\n",
    "For illustration, we focus on Grade 1 students. We first extract and transform the predictions back to the original scale of test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mask = (\n",
    "    raw_df_control_grid.select(pl.col(\"grade\").eq(pl.lit(1))).to_numpy().flatten()\n",
    ")\n",
    "control_posterior_grade = posterior_predictive_control[\"posterior_predictive\"][\n",
    "    \"mu_outcome\"\n",
    "][:, :, control_mask]\n",
    "\n",
    "original_scale_control_posterior_grade = (\n",
    "    control_posterior_grade\n",
    "    * preprocessor[\"num\"].scale_[numeric_features.index(\"post_test\")]\n",
    "    + preprocessor[\"num\"].mean_[numeric_features.index(\"post_test\")]\n",
    ")\n",
    "\n",
    "treatment_mask = (\n",
    "    raw_df_treatment_grid.select(pl.col(\"grade\").eq(pl.lit(1))).to_numpy().flatten()\n",
    ")\n",
    "treatment_posterior_grade = posterior_predictive_treatment[\"posterior_predictive\"][\n",
    "    \"mu_outcome\"\n",
    "][:, :, treatment_mask]\n",
    "\n",
    "original_scale_treatment_posterior_grade = (\n",
    "    treatment_posterior_grade\n",
    "    * preprocessor[\"num\"].scale_[numeric_features.index(\"post_test\")]\n",
    "    + preprocessor[\"num\"].mean_[numeric_features.index(\"post_test\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e81dc6",
   "metadata": {},
   "source": [
    "We now visualize the posterior distribution of the average treatment effect for Grade 1. The first plot shows the effect computed from the counterfactual predictions, while the second shows the direct coefficient estimate. These should be consistent, providing a validation of our approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(\n",
    "    (\n",
    "        original_scale_treatment_posterior_grade\n",
    "        - original_scale_control_posterior_grade\n",
    "    ).mean(dim=(\"obs_idx\"))\n",
    ")\n",
    "az.plot_posterior(\n",
    "    (\n",
    "        idata[\"posterior\"][\"beta_treatment\"]\n",
    "        * preprocessor[\"num\"].scale_[numeric_features.index(\"post_test\")]\n",
    "    ).sel(grade=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da5d251",
   "metadata": {},
   "source": [
    "Both approaches yield similar posterior distributions, confirming the robustness of our causal effect estimate. The positive treatment effect indicates that watching \"The Electric Company\" improved reading scores for Grade 1 students. The credible intervals quantify our uncertainty about the magnitude of this effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee33b6f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---\n",
    "## Part 2: Covariance Model\n",
    "\n",
    "### Motivation: Modeling Treatment Effect Heterogeneity\n",
    "\n",
    "The hierarchical intercept model in Part 1 assumes that the treatment effect is constant across all pairs (after accounting for grade differences). While this model efficiently controls for pair-level confounding, it does not allow us to explore whether the treatment effect varies across pairs. In practice, some schools or classrooms may respond more strongly to the intervention than others due to unmeasured factors such as teacher implementation fidelity, student engagement, or local context.\n",
    "\n",
    "To capture this **treatment effect heterogeneity**, we extend our model to allow both the baseline intercept $\\alpha_j$ and the treatment effect $\\theta_j$ to vary across pairs. Moreover, we model the joint distribution of these pair-specific parameters using a bivariate normal distribution with a covariance structure:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix} \\alpha_j \\\\ \\theta_j \\end{pmatrix} \\sim N\\left(\\begin{pmatrix} \\mu_\\alpha \\\\ \\mu_\\theta \\end{pmatrix}, \\Sigma\\right)\n",
    "$$\n",
    "\n",
    "where $\\Sigma$ is a $2 \\times 2$ covariance matrix. The off-diagonal elements of $\\Sigma$ capture the correlation between baseline performance and treatment response. For example, a positive correlation would indicate that pairs with higher baseline scores also tend to experience larger treatment effects, while a negative correlation would suggest compensatory effects (treatment helps struggling pairs more).\n",
    "\n",
    "#### Benefits of Modeling Covariances\n",
    "\n",
    "This approach represents what Huntington-Klein (2021, *The Effect*, Chapter 16) calls \"Advanced Random Effects\" or multi-level modeling. By explicitly modeling the covariance structure, we gain several advantages over both standard Fixed Effects and basic Random Effects:\n",
    "\n",
    "-   **Captures heterogeneity**: We estimate not just the average treatment effect $\\mu_\\theta$, but also the distribution of pair-specific effects $\\theta_j$, revealing how treatment impacts vary across contexts.\n",
    "-   **Partial pooling on treatment effects**: Noisy pair-specific estimates are shrunk toward the population mean, borrowing strength across groups. This provides more stable estimates than treating each pair entirely separately.\n",
    "-   **Correlation structure**: We learn whether baseline performance and treatment response are related, which can inform targeting and generalization of the intervention. This addresses the limitation of basic Random Effects by explicitly modeling the relationship between group characteristics and effects.\n",
    "-   **Separation of between and within effects**: By allowing both intercepts and slopes to vary, we can distinguish population-level patterns from group-specific deviations, providing richer substantive interpretation.\n",
    "-   **Efficiency with hierarchical data**: Multi-level models make full use of the hierarchical structure, improving statistical efficiency compared to Fixed Effects while relaxing the strong independence assumptions of basic Random Effects.\n",
    "\n",
    "We implement this model using a non-centered parametrization with a Cholesky decomposition of the covariance matrix for computational efficiency. The following helper functions construct correlation and covariance matrices in a vectorized manner for each grade level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_correlation_matrices(corr_values, size=2):\n",
    "    n_matrices = corr_values.shape[0]\n",
    "\n",
    "    # Reshape for broadcasting\n",
    "    # Use reshape or expand_dims instead of dimshuffle\n",
    "    corr_expanded = pt.reshape(corr_values, (n_matrices, 1, 1))\n",
    "\n",
    "    # Create base: all elements are correlation values\n",
    "    base = corr_expanded * pt.ones((n_matrices, size, size))\n",
    "\n",
    "    # Create diagonal mask\n",
    "    diag_mask = pt.eye(size, dtype=\"bool\")\n",
    "\n",
    "    # Set diagonal to 1\n",
    "    return pt.where(diag_mask, 1.0, base)\n",
    "\n",
    "\n",
    "def vectorized_diagonal_matrices_v4(values):\n",
    "    k = values.shape[1]  # 2\n",
    "\n",
    "    # Create identity matrix (2, 2)\n",
    "    identity_matrix = pt.eye(k)\n",
    "\n",
    "    # Reshape values for broadcasting: (4, 2) -> (4, 2, 1)\n",
    "    values_expanded = values[:, :, None]\n",
    "\n",
    "    # Multiply: (4, 2, 1) * (2, 2) -> (4, 2, 2)\n",
    "    # This puts values[i, j] at position [i, j, j]\n",
    "    return values_expanded * identity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6e4f49",
   "metadata": {},
   "source": [
    "### Prior Specification for Correlation\n",
    "\n",
    "Before specifying the full model, we visualize our prior distribution for the correlation parameter. We use a Beta(20, 4) distribution (scaled to [-1, 1]) to encode a prior belief that the correlation between intercepts and treatment effects is likely positive but with substantial uncertainty. This prior is weakly informative and allows the data to dominate the posterior inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93259c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pz.Beta(alpha=20, beta=4).plot_pdf(pointinterval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc180f",
   "metadata": {},
   "source": [
    "The Beta distribution shown above is transformed to the correlation scale via the mapping $\\rho = 2 \\times \\text{Beta}(20, 4) - 1$. This induces a prior that favors positive correlations but remains flexible enough to accommodate a range of values.\n",
    "\n",
    "### Model Specification\n",
    "\n",
    "We now specify the full covariance model. The key difference from Part 1 is that both the intercept and the treatment effect vary by pair. The model structure is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{post\\_test}_i &\\sim N(\\mu_i, \\sigma_y) \\\\\n",
    "\\mu_i &= \\alpha_{\\text{pair}[i]} + \\theta_{\\text{pair}[i]} \\cdot T_i + \\beta_x \\cdot \\text{pre\\_test}_i \\\\\n",
    "\\begin{pmatrix} \\alpha_j \\\\ \\theta_j \\end{pmatrix} &\\sim N\\left(\\begin{pmatrix} \\mu_\\alpha \\\\ \\mu_\\theta \\end{pmatrix}, \\Sigma\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $\\Sigma$ is decomposed as $\\Sigma = D \\Omega D$, with $D$ being a diagonal matrix of standard deviations and $\\Omega$ being the correlation matrix. This decomposition allows us to place separate priors on the marginal variances and the correlation structure, which improves interpretability and sampling efficiency.\n",
    "\n",
    "The non-centered parametrization introduces a latent variable $u_{\\text{raw}} \\sim N(0, I)$ and transforms it via the Cholesky factor of $\\Sigma$ to obtain the correlated random effects $(u_0, u_1)$ corresponding to $(\\alpha_j - \\mu_\\alpha, \\theta_j - \\mu_\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe0bc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords.update({\"effect\": [\"intercept\", \"slope\"], \"effect_copy\": [\"intercept\", \"slope\"]})\n",
    "coords.update({\"corr_dim\": [\"corr_dim_1\"]})\n",
    "\n",
    "\n",
    "with pm.Model(coords=coords) as cov_model:\n",
    "    # --- Data Containers ---\n",
    "    # covariates\n",
    "    x_data = pm.Data(\"x_data\", x_df, dims=(\"obs_idx\", \"covariates\"))\n",
    "    # grade\n",
    "    grade_idx_data = pm.Data(\"grade_idx_data\", df[\"grade\"].to_numpy(), dims=\"obs_idx\")\n",
    "    # object categories\n",
    "    pair_idx_data = pm.Data(\"pair_idx_data\", df[\"pair_id\"].to_numpy(), dims=\"obs_idx\")\n",
    "    # treatment\n",
    "    treatment_data = pm.Data(\n",
    "        \"treatment_data\", df[\"treatment\"].to_numpy(), dims=(\"obs_idx\")\n",
    "    )\n",
    "    # outcome\n",
    "    post_test_data = pm.Data(\n",
    "        \"post_test_data\", df[\"post_test\"].to_numpy(), dims=\"obs_idx\"\n",
    "    )\n",
    "\n",
    "    # --- Priors ---\n",
    "\n",
    "    beta_x = pm.Normal(\"beta_x\", mu=0, sigma=1, dims=(\"grade\", \"covariates\"))\n",
    "    sigma_outcome = pm.HalfNormal(\"sigma_outcome\", sigma=1, dims=(\"grade\"))\n",
    "\n",
    "    mu_alpha = pm.Normal(\"mu_alpha\", mu=0, sigma=0.5, dims=(\"grade\"))\n",
    "    mu_theta = pm.Normal(\"mu_theta\", mu=0, sigma=0.5, dims=(\"grade\"))\n",
    "\n",
    "    # Group-level standard deviations\n",
    "    sigma_u = pm.HalfNormal(\n",
    "        \"sigma_u\", sigma=np.array([0.2, 0.2]), dims=(\"grade\", \"effect\")\n",
    "    )\n",
    "\n",
    "    # Triangular upper part of the correlation matrix\n",
    "    # omega_triu = pm.LKJCorr(\"omega_triu\", eta=1, n=2, dims=(\"grade\", \"corr_dim\"))\n",
    "    omega_triu = pm.Beta(\"omega_triu\", alpha=20, beta=4, dims=(\"grade\", \"corr_dim\"))\n",
    "    omega_triu_scaled = omega_triu * 2 - 1\n",
    "\n",
    "    # Construct correlation matrix\n",
    "    omega = pm.Deterministic(\n",
    "        \"omega\",\n",
    "        vectorized_correlation_matrices(omega_triu_scaled),\n",
    "        dims=(\"grade\", \"effect\", \"effect_copy\"),\n",
    "    )\n",
    "\n",
    "    # Construct diagonal matrix of standard deviation\n",
    "    sigma_diagonal = pm.Deterministic(\n",
    "        \"sigma_diagonal\",\n",
    "        vectorized_diagonal_matrices_v4(sigma_u),\n",
    "        dims=(\"grade\", \"effect\", \"effect_copy\"),\n",
    "    )\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov = pm.Deterministic(\n",
    "        \"cov\",\n",
    "        pt.einsum(\"bij,bjk,bkl->bil\", sigma_diagonal, omega, sigma_diagonal),\n",
    "        dims=(\"grade\", \"effect\", \"effect_copy\"),\n",
    "    )\n",
    "\n",
    "    # Cholesky decomposition of covariance matrix\n",
    "    cholesky_cov = pm.Deterministic(\n",
    "        \"cholesky_cov\",\n",
    "        pt.slinalg.cholesky(cov),\n",
    "        dims=(\"grade\", \"effect\", \"effect_copy\"),\n",
    "    )\n",
    "\n",
    "    # And finally get group-specific coefficients\n",
    "    u_raw = pm.Normal(\"u_raw\", mu=0, sigma=1, dims=(\"grade\", \"effect\", \"pair_id\"))\n",
    "    u = pm.Deterministic(\n",
    "        \"u\",\n",
    "        pt.einsum(\"bik,bkj->bji\", cholesky_cov, u_raw),\n",
    "        dims=(\"grade\", \"pair_id\", \"effect\"),\n",
    "    )\n",
    "\n",
    "    u0 = pm.Deterministic(\"u0\", u[:, :, 0], dims=(\"grade\", \"pair_id\"))\n",
    "    u1 = pm.Deterministic(\"u1\", u[:, :, 1], dims=(\"grade\", \"pair_id\"))\n",
    "\n",
    "    alpha = pm.Deterministic(\"alpha\", mu_alpha + u0.T, dims=(\"pair_id\", \"grade\"))\n",
    "    theta = pm.Deterministic(\"theta\", mu_theta + u1.T, dims=(\"pair_id\", \"grade\"))\n",
    "\n",
    "    mu_outcome = pm.Deterministic(\n",
    "        \"mu_outcome\",\n",
    "        alpha[pair_idx_data, grade_idx_data]\n",
    "        + theta[pair_idx_data, grade_idx_data] * treatment_data\n",
    "        + (beta_x[grade_idx_data] * x_data).sum(axis=-1),\n",
    "        dims=(\"obs_idx\"),\n",
    "    )\n",
    "\n",
    "    # --- Likelihood ---\n",
    "    pm.Normal(\n",
    "        \"post_test_obs\",\n",
    "        mu=mu_outcome,\n",
    "        sigma=sigma_outcome[grade_idx_data],\n",
    "        observed=post_test_data,\n",
    "        dims=\"obs_idx\",\n",
    "    )\n",
    "\n",
    "pm.model_to_graphviz(cov_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07593a",
   "metadata": {},
   "source": [
    "The graphical model representation shows the more complex dependency structure: now both `alpha` and `theta` are hierarchical parameters that depend on the covariance structure (`cov`), which itself is constructed from standard deviations (`sigma_u`) and correlations (`omega`).\n",
    "\n",
    "### Prior Predictive Check\n",
    "\n",
    "As in Part 1, we sample from the prior distribution to verify that our priors produce reasonable predictions before observing the data. This is especially important for the covariance model, where the additional flexibility could lead to implausible outcomes if priors are poorly calibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e2e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with cov_model:\n",
    "    cov_idata = pm.sample_prior_predictive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6383a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "az.plot_ppc(cov_idata, group=\"prior\", ax=ax)\n",
    "az.plot_dist(df[\"post_test\"].to_numpy(), color=\"black\", ax=ax)\n",
    "ax.set_title(\n",
    "    \"Prior Predictive Check - Covariance Model\", fontsize=18, fontweight=\"bold\", y=1.02\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced85e99",
   "metadata": {},
   "source": [
    "The prior predictive distribution (blue) encompasses the observed data (black), indicating that our priors are compatible with the data while remaining sufficiently diffuse to avoid imposing strong assumptions. The prior allows for substantial variation in both intercepts and treatment effects across pairs.\n",
    "\n",
    "### Posterior Inference\n",
    "\n",
    "We now fit the covariance model using HMC. Due to the increased complexity of the model (additional parameters and correlation structure), we use a longer tuning phase (2,000 iterations) and a higher target acceptance rate (0.95) to ensure thorough exploration of the posterior geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "with cov_model:\n",
    "    cov_idata.extend(\n",
    "        pm.sample(\n",
    "            tune=2_000,\n",
    "            draws=1_000,\n",
    "            chains=4,\n",
    "            nuts_sampler=\"numpyro\",\n",
    "            target_accept=0.95,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cov_idata.extend(pm.sample_posterior_predictive(cov_idata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79675e74",
   "metadata": {},
   "source": [
    "Posterior sampling is complete. We generated 4,000 posterior draws (1,000 per chain) along with posterior predictive samples for model checking.\n",
    "\n",
    "### Model Diagnostics\n",
    "\n",
    "We examine diagnostic statistics to ensure the sampler converged successfully. The covariance model has a more complex posterior geometry, so careful attention to diagnostics is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# az.summary(\n",
    "#     slopes_idata,\n",
    "#     var_names=[\n",
    "#         \"beta_x\",\n",
    "#         \"mu_alpha\",\n",
    "#         \"sigma_alpha\",\n",
    "#         \"mu_treatment\",\n",
    "#         \"sigma_treatment\",\n",
    "#         \"sigma_outcome\",\n",
    "#     ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b989cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_idata[\"sample_stats\"][\"diverging\"].sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd42d3",
   "metadata": {},
   "source": [
    "The absence of divergent transitions indicates successful sampling. The more complex model structure did not cause problematic posterior geometry, which validates our use of the non-centered parametrization and appropriate tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c32b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "az.plot_ppc(cov_idata, group=\"posterior\", num_pp_samples=500, ax=ax)\n",
    "ax.set_title(\n",
    "    \"Posterior Predictive Check - Covariance Model\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    y=1.02,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8913bd",
   "metadata": {},
   "source": [
    "The posterior predictive check shows excellent agreement between the model predictions and observed data. The covariance model, despite its additional flexibility, does not overfit and continues to capture the essential data patterns.\n",
    "\n",
    "### Treatment Effect Estimates\n",
    "\n",
    "We now examine the estimated treatment effects from the covariance model. Unlike Part 1, where we had a single treatment effect parameter per grade, here we have a population-level mean treatment effect (`mu_theta`) and pair-specific deviations from this mean (`theta`). The parameter `mu_theta` represents the average causal effect across all pairs within a grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd95822",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "az.plot_forest(\n",
    "    cov_idata,\n",
    "    combined=True,\n",
    "    var_names=[\"mu_theta\"],\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708b80b",
   "metadata": {},
   "source": [
    "The forest plot shows the posterior distribution of the average treatment effect (`mu_theta`) for each grade. These estimates are comparable to the `beta_treatment` estimates from Part 1, but they now represent the mean of a distribution of pair-specific effects rather than a fixed common effect.\n",
    "\n",
    "### Hierarchical Shrinkage: Population vs. Group-Level Effects\n",
    "\n",
    "One of the key advantages of the covariance model is that it allows us to estimate both population-level parameters (the means $\\mu_\\alpha$ and $\\mu_\\theta$) and group-level parameters (the pair-specific $\\alpha_j$ and $\\theta_j$). Through partial pooling, the model borrows strength across pairs: estimates for pairs with sparse data are shrunk toward the population mean, while estimates for data-rich pairs are allowed to deviate more.\n",
    "\n",
    "The visualization below compares population-level and group-level estimates for Grade 1. The top row shows the population means ($\\mu_\\alpha$ and $\\mu_\\theta$), while the bottom row shows the distribution of pair-specific effects ($\\alpha_j$ and $\\theta_j$) for pairs within Grade 1. The degree of shrinkage depends on the estimated between-pair variance: if pairs are highly similar, estimates will be heavily pooled; if pairs differ substantially, estimates will retain more individual variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=2,\n",
    "    height_ratios=[0.3, 1],\n",
    "    figsize=(12, 7),\n",
    "    sharex=True,\n",
    "    sharey=False,\n",
    "    layout=\"constrained\",\n",
    ")\n",
    "\n",
    "az.plot_forest(\n",
    "    cov_idata[\"posterior\"].sel(grade=1),\n",
    "    combined=True,\n",
    "    var_names=[\"mu_alpha\"],\n",
    "    colors=\"C0\",\n",
    "    ax=ax[0, 0],\n",
    ")\n",
    "\n",
    "\n",
    "az.plot_forest(\n",
    "    cov_idata[\"posterior\"]\n",
    "    .sel(grade=1)\n",
    "    .where(\n",
    "        cov_idata[\"posterior\"].pair_id.isin(\n",
    "            raw_df.group_by(\"grade\")\n",
    "            .agg(pl.col(\"pair_id\").unique())\n",
    "            .filter(pl.col(\"grade\").eq(pl.lit(1)))[\"pair_id\"]\n",
    "            .to_list()\n",
    "        ),\n",
    "        drop=True,\n",
    "    ),\n",
    "    var_names=[\"alpha\"],\n",
    "    combined=True,\n",
    "    colors=\"C1\",\n",
    "    ax=ax[1, 0],\n",
    ")\n",
    "\n",
    "\n",
    "az.plot_forest(\n",
    "    cov_idata[\"posterior\"].sel(grade=1),\n",
    "    combined=True,\n",
    "    var_names=[\"mu_theta\"],\n",
    "    colors=\"C0\",\n",
    "    ax=ax[0, 1],\n",
    ")\n",
    "\n",
    "\n",
    "az.plot_forest(\n",
    "    cov_idata[\"posterior\"]\n",
    "    .sel(grade=1)\n",
    "    .where(\n",
    "        cov_idata[\"posterior\"].pair_id.isin(\n",
    "            raw_df.group_by(\"grade\")\n",
    "            .agg(pl.col(\"pair_id\").unique())\n",
    "            .filter(pl.col(\"grade\").eq(pl.lit(1)))[\"pair_id\"]\n",
    "            .to_list()\n",
    "        ),\n",
    "        drop=True,\n",
    "    ),\n",
    "    var_names=[\"theta\"],\n",
    "    combined=True,\n",
    "    colors=\"C1\",\n",
    "    ax=ax[1, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af632f6f",
   "metadata": {},
   "source": [
    "This panel plot reveals several important features of the hierarchical model:\n",
    "\n",
    "-   **Left column (Intercepts)**: The top panel shows the population-level mean intercept for Grade 1 ($\\mu_\\alpha$). The bottom panel shows the distribution of pair-specific intercepts ($\\alpha_j$). The spread of the pair-specific estimates reflects genuine between-pair heterogeneity in baseline performance, while the concentration around the mean reflects partial pooling.\n",
    "\n",
    "-   **Right column (Treatment Effects)**: The top panel shows the population-level mean treatment effect ($\\mu_\\theta$). The bottom panel shows pair-specific treatment effects ($\\theta_j$). Some pairs exhibit treatment effects above the mean, others below, capturing treatment effect heterogeneity. The varying widths of the credible intervals reflect differences in information content across pairs: pairs with more data have narrower intervals.\n",
    "\n",
    "-   **Interpretation**: The covariance structure allows the model to learn whether pairs with high baseline scores (large $\\alpha_j$) also tend to have large treatment effects (large $\\theta_j$). This correlation, encoded in the off-diagonal elements of $\\Sigma$, can inform policy decisions about targeting interventions.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This analysis demonstrates how multilevel models provide a principled framework for causal inference in clustered data, combining the virtues of experimental design with efficient statistical estimation. We estimated the causal effect of watching \"The Electric Company\" on reading scores using two complementary hierarchical models, each offering distinct insights and tradeoffs.\n",
    "\n",
    "### Summary of Findings\n",
    "\n",
    "Both models provide evidence of a **positive causal effect** of the television program on reading test scores:\n",
    "-   **Part 1 (Hierarchical Intercept Model)**: We estimated a common treatment effect within each grade while allowing baseline performance to vary across pairs. The treatment effect estimates were consistently positive, indicating that exposure to the show improved reading outcomes.\n",
    "-   **Part 2 (Covariance Model)**: We extended the model to allow treatment effects themselves to vary across pairs, capturing treatment effect heterogeneity. The population-level mean treatment effects ($\\mu_\\theta$) were similar to those from Part 1, but we also learned about the distribution of pair-specific effects and their correlation with baseline performance.\n",
    "\n",
    "### Comparing the Two Approaches\n",
    "\n",
    "**When to use the Hierarchical Intercept Model (Part 1):**\n",
    "-   You have strong theoretical or empirical reasons to believe treatment effects are homogeneous (constant across groups).\n",
    "-   Sample sizes within groups are small, making estimation of group-specific treatment effects unreliable.\n",
    "-   Parsimony is important, and you wish to maximize statistical power for detecting the average treatment effect.\n",
    "-   The primary research question concerns the average effect, not effect heterogeneity.\n",
    "\n",
    "**When to use the Covariance Model (Part 2):**\n",
    "-   You expect treatment effects to vary across groups and want to quantify this heterogeneity.\n",
    "-   You have sufficient data within groups to estimate group-specific effects reliably.\n",
    "-   You are interested in understanding the relationship between baseline characteristics and treatment response (e.g., do struggling students benefit more?).\n",
    "-   Policy decisions depend on targeting: knowing which subgroups respond most strongly to the intervention.\n",
    "\n",
    "In our case, both models converged successfully and produced consistent estimates of the average treatment effect. The covariance model revealed modest variation in treatment effects across pairs, though the primary conclusion—that the program had a positive effect—remained robust across specifications.\n",
    "\n",
    "### Methodological Contributions\n",
    "\n",
    "This example illustrates several important principles for causal inference with multilevel data:\n",
    "\n",
    "1.  **Accounting for Clustering**: Observations within pairs are not independent. Ignoring this dependence would yield overconfident (too narrow) standard errors and invalid inference. Multilevel models correctly account for within-group correlation.\n",
    "\n",
    "2.  **Efficiency Through Partial Pooling**: Rather than estimating separate parameters for each pair (Fixed Effects) or ignoring group structure entirely (Complete Pooling), hierarchical models implement partial pooling. Group-specific estimates are shrunk toward the population mean in proportion to their uncertainty, borrowing strength across groups and improving efficiency.\n",
    "\n",
    "3.  **Validity of Random Effects in Randomized Designs**: A common concern in econometrics is that Random Effects models assume group effects are uncorrelated with predictors, potentially leading to bias. This concern motivates the preference for Fixed Effects in many observational studies (Huntington-Klein, 2021). However, in our paired randomized design, treatment was assigned randomly **within pairs**. This ensures that treatment assignment is independent of pair-level characteristics by design, making the Random Effects assumption valid for the causal estimand. The randomization mechanism itself guarantees the required independence, eliminating the usual concern about endogeneity. See Gelman and Hill (2006, Chapter 23) for the original exposition of this application.\n",
    "\n",
    "4.  **Flexible Modeling of Heterogeneity**: The covariance model demonstrates how to move beyond constant treatment effects. By modeling the joint distribution of intercepts and slopes, we can capture complex patterns of heterogeneity and learn about relationships between baseline characteristics and treatment response. This multi-level approach, as described in Huntington-Klein (2021, Chapter 16, \"Advanced Random Effects\"), explicitly models the correlation between group effects and outcomes, addressing the limitations of both basic Random Effects (which ignore such correlations) and Fixed Effects (which cannot estimate them).\n",
    "\n",
    "5.  **Bayesian Workflow**: We followed a principled Bayesian workflow: prior predictive checks to validate priors, posterior diagnostics to ensure convergence, posterior predictive checks to assess fit, and interpretable visualizations of both population-level and group-level effects.\n",
    "\n",
    "### Broader Implications\n",
    "\n",
    "The methods demonstrated here extend naturally to other settings with clustered data and causal questions:\n",
    "-   **Education**: Students nested within schools; teachers nested within districts.\n",
    "-   **Healthcare**: Patients nested within hospitals; repeated measurements within patients.\n",
    "-   **Economics**: Individuals nested within regions; firms nested within industries.\n",
    "-   **Marketing**: Customers nested within stores; experimental units nested within markets.\n",
    "\n",
    "In all these contexts, multilevel models allow researchers to respect the hierarchical structure of data while efficiently estimating causal effects. They provide a middle ground between the extremes of ignoring group structure (potentially invalid inference) and treating groups as entirely separate (potentially inefficient inference).\n",
    "\n",
    "### References\n",
    "\n",
    "-   Gelman, A., & Hill, J. (2006). *Data Analysis Using Regression and Multilevel/Hierarchical Models*. Cambridge University Press. Chapter 23: Causal Inference Using Multilevel Models.\n",
    "-   Huntington-Klein, N. (2021). *The Effect: An Introduction to Research Design and Causality*. Chapman and Hall/CRC. Chapter 16: Fixed Effects. Available online at https://theeffectbook.net/ch-FixedEffects.html\n",
    "\n",
    "This analysis demonstrates that multilevel models are not merely a technical tool for handling clustered data—they are a fundamental framework for causal inference that bridges experimental design, statistical efficiency, and substantive interpretation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
