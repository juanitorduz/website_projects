{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f27dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import pairwise\n",
    "\n",
    "import arviz as az\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "import optax\n",
    "from flax import nnx\n",
    "from jax import random\n",
    "from jaxtyping import Array, Float, Int\n",
    "from numpyro.contrib.module import nnx_module\n",
    "from numpyro.handlers import do, seed, trace\n",
    "from numpyro.infer import SVI, Predictive, Trace_ELBO\n",
    "from numpyro.infer.autoguide import AutoNormal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "numpyro.set_host_device_count(n=10)\n",
    "\n",
    "rng_key = random.PRNGKey(seed=42)\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 7]\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext jaxtyping\n",
    "%jaxtyping.typechecker beartype.beartype\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerationParameters(BaseModel):\n",
    "    num_train: int\n",
    "    num_test: int\n",
    "    feature_dim: int\n",
    "    z_gap: float\n",
    "    y_gap: float\n",
    "\n",
    "\n",
    "data_generation_parameters = DataGenerationParameters(\n",
    "    num_train=10_000,\n",
    "    num_test=2_000,\n",
    "    feature_dim=10,\n",
    "    z_gap=1.0,\n",
    "    y_gap=3.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293aa9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(\n",
    "    num_data: int, feature_dim: int, z_gap: float, y_gap: float\n",
    ") -> tuple[\n",
    "    Float[Array, \"num_data feature_dim\"],\n",
    "    Int[Array, \" num_data\"],\n",
    "    Int[Array, \" num_data\"],\n",
    "    Int[Array, \" num_data\"],\n",
    "    Int[Array, \" num_data\"],\n",
    "]:\n",
    "    # Latent confounder z is binary.\n",
    "    with numpyro.plate(\"num_data\", num_data):\n",
    "        z = numpyro.sample(\"z\", dist.Bernoulli(0.5))\n",
    "\n",
    "        # Covariates x are normally distributed, with higher variance for z=1.\n",
    "        with numpyro.plate(\"feature_dim\", feature_dim):\n",
    "            x = numpyro.sample(\"x\", dist.Normal(z * z_gap, 5 * z + 3 * (1 - z))).T\n",
    "\n",
    "        # Treatment t is binary, with higher probability for z=1.\n",
    "        t = numpyro.sample(\"t\", dist.Bernoulli(0.75 * z + 0.25 * (1 - z)))\n",
    "\n",
    "        # Outcome y is binary, with higher probability for z=1 and t=1.\n",
    "        y = numpyro.sample(\"y\", dist.Bernoulli(logits=y_gap * (z + 2 * (2 * t - 1))))\n",
    "\n",
    "        # Compute true c-specific CATE for evaluation.\n",
    "        t0_t1 = jnp.array([[0.0], [1.0]])\n",
    "        y_t0_t1 = numpyro.sample(\n",
    "            \"y_t0_t1\", dist.Bernoulli(logits=y_gap * (z + 2 * (2 * t0_t1 - 1)))\n",
    "        )\n",
    "\n",
    "        y_t0 = y_t0_t1[0]\n",
    "        y_t1 = y_t0_t1[1]\n",
    "\n",
    "        true_cates = y_t1 - y_t0\n",
    "\n",
    "        return (x, t, y, z, true_cates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyro.render_model(\n",
    "    generate_data,\n",
    "    model_kwargs={\n",
    "        \"num_data\": data_generation_parameters.num_train,\n",
    "        \"feature_dim\": data_generation_parameters.feature_dim,\n",
    "        \"z_gap\": data_generation_parameters.z_gap,\n",
    "        \"y_gap\": data_generation_parameters.y_gap,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train: Float[Array, \"num_train feature_dim\"]\n",
    "t_train: Int[Array, \" num_train\"]\n",
    "y_train: Int[Array, \" num_train\"]\n",
    "\n",
    "rng_key, rng_subkey = random.split(rng_key)\n",
    "\n",
    "x_train, t_train, y_train, _, _ = trace(seed(generate_data, rng_subkey))(\n",
    "    num_data=data_generation_parameters.num_train,\n",
    "    feature_dim=data_generation_parameters.feature_dim,\n",
    "    z_gap=data_generation_parameters.z_gap,\n",
    "    y_gap=data_generation_parameters.y_gap,\n",
    ")\n",
    "\n",
    "\n",
    "x_test: Float[Array, \"feature_dim num_test\"]\n",
    "z_test: Int[Array, \" num_test\"]\n",
    "true_cates: Float[Array, \" num_test\"]\n",
    "\n",
    "x_test, _, _, z_test, true_cates = trace(seed(generate_data, rng_subkey))(\n",
    "    num_data=data_generation_parameters.num_test,\n",
    "    feature_dim=data_generation_parameters.feature_dim,\n",
    "    z_gap=data_generation_parameters.z_gap,\n",
    "    y_gap=data_generation_parameters.y_gap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fe19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(nnx.Module):\n",
    "    def __init__(\n",
    "        self, din: int, dout: int, hidden_layers: list[int], *, rngs: nnx.Rngs\n",
    "    ) -> None:\n",
    "        self.layers = nnx.List([])\n",
    "\n",
    "        layer_dims = [din, *hidden_layers, dout]\n",
    "\n",
    "        for in_dim, out_dim in pairwise(layer_dims):\n",
    "            self.layers.append(nnx.Linear(in_dim, out_dim, rngs=rngs))\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        for layer in self.layers:\n",
    "            x = jax.nn.elu(layer(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiagNormalNet(FullyConnected):\n",
    "    def __init__(\n",
    "        self, din: int, dout: int, hidden_layers: list[int], *, rngs: nnx.Rngs\n",
    "    ):\n",
    "        super().__init__(din=din, dout=2 * dout, hidden_layers=hidden_layers, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array) -> tuple[Array, Array]:\n",
    "        loc, scale = jnp.split(super().__call__(x), 2, axis=-1)\n",
    "        return loc, jax.nn.softplus(scale)\n",
    "\n",
    "\n",
    "class BernoulliNet(FullyConnected):\n",
    "    def __init__(\n",
    "        self, din: int, dout: int, hidden_layers: list[int], *, rngs: nnx.Rngs\n",
    "    ):\n",
    "        super().__init__(din, dout, hidden_layers, rngs=rngs)\n",
    "\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        return jnp.clip(super().__call__(x), a_min=-10, a_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParameters(BaseModel):\n",
    "    feature_dim: int\n",
    "    hidden_dim: int\n",
    "    latent_dim: int\n",
    "    num_layers: int\n",
    "\n",
    "\n",
    "model_parameters = ModelParameters(\n",
    "    feature_dim=x_train.shape[1],\n",
    "    latent_dim=5,\n",
    "    hidden_dim=200,\n",
    "    num_layers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afafe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key, rng_subkey = random.split(rng_key)\n",
    "\n",
    "x_nn_module = DiagNormalNet(\n",
    "    din=model_parameters.latent_dim,\n",
    "    dout=model_parameters.feature_dim,\n",
    "    hidden_layers=[model_parameters.hidden_dim] * model_parameters.num_layers,\n",
    "    rngs=nnx.Rngs(rng_subkey),\n",
    ")\n",
    "\n",
    "t_nn_module = BernoulliNet(\n",
    "    din=model_parameters.latent_dim,\n",
    "    dout=1,\n",
    "    hidden_layers=[1],\n",
    "    rngs=nnx.Rngs(rng_subkey),\n",
    ")\n",
    "\n",
    "y_nn_0_module = BernoulliNet(\n",
    "    din=model_parameters.latent_dim,\n",
    "    dout=1,\n",
    "    hidden_layers=[model_parameters.hidden_dim] * model_parameters.num_layers,\n",
    "    rngs=nnx.Rngs(rng_subkey),\n",
    ")\n",
    "\n",
    "y_nn_1_module = BernoulliNet(\n",
    "    din=model_parameters.latent_dim,\n",
    "    dout=1,\n",
    "    hidden_layers=[model_parameters.hidden_dim] * model_parameters.num_layers,\n",
    "    rngs=nnx.Rngs(rng_subkey),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax._src.basearray import Array\n",
    "\n",
    "rng_key, rng_subkey = random.split(rng_key)\n",
    "\n",
    "x_nn_module = DiagNormalNet(\n",
    "    din=model_parameters.latent_dim,\n",
    "    dout=model_parameters.feature_dim,\n",
    "    hidden_layers=[model_parameters.latent_dim]\n",
    "    + [model_parameters.hidden_dim] * model_parameters.num_layers\n",
    "    + [model_parameters.feature_dim],\n",
    "    rngs=nnx.Rngs(rng_subkey),\n",
    ")\n",
    "\n",
    "\n",
    "def model(\n",
    "    x: Float[Array, \"num_data feature_dim\"],\n",
    "    t: Int[Array, \" num_data\"],\n",
    "    y: Int[Array, \" num_data\"],\n",
    "    latent_dim: int = 5,\n",
    ") -> None:\n",
    "    num_data, n_features = x.shape\n",
    "\n",
    "    with numpyro.plate(\"latent_dim\", latent_dim):\n",
    "        z = numpyro.sample(\"z\", dist.Normal(0, 1))\n",
    "\n",
    "    x_nn = nnx_module(\"x_nn\", x_nn_module)\n",
    "    x_nn_z = x_nn(z)\n",
    "\n",
    "    x_loc = x_nn_z[0][None, :]\n",
    "    x_scale = x_nn_z[1][None, :]\n",
    "\n",
    "    numpyro.sample(\n",
    "        \"x_obs\",\n",
    "        dist.Normal(x_loc, x_scale).expand([num_data, n_features]).to_event(2),\n",
    "        obs=x,\n",
    "    )\n",
    "\n",
    "    t_nn = nnx_module(\"t_nn\", t_nn_module)\n",
    "    t_nn_z = t_nn(z)\n",
    "\n",
    "    t_obs = numpyro.sample(\n",
    "        \"t_obs\",\n",
    "        dist.Bernoulli(logits=t_nn_z).expand([num_data]).to_event(1),\n",
    "        obs=t,\n",
    "    )\n",
    "\n",
    "    y_nn_0 = nnx_module(\"y_nn_0\", y_nn_0_module)\n",
    "    y_nn_0_z = y_nn_0(z)\n",
    "\n",
    "    y_nn_1 = nnx_module(\"y_nn_1\", y_nn_1_module)\n",
    "    y_nn_1_z = y_nn_1(z)\n",
    "\n",
    "    y_logits = jnp.where(t_obs == 0, y_nn_0_z, y_nn_1_z)\n",
    "    y_probs = numpyro.deterministic(\"y_probs\", jax.nn.sigmoid(y_logits))\n",
    "\n",
    "    numpyro.sample(\n",
    "        \"y_obs\",\n",
    "        dist.Bernoulli(probs=y_probs).expand([num_data]).to_event(1),\n",
    "        obs=y,\n",
    "    )\n",
    "\n",
    "\n",
    "numpyro.render_model(\n",
    "    model,\n",
    "    model_kwargs={\n",
    "        \"x\": x_train,\n",
    "        \"t\": t_train,\n",
    "        \"y\": y_train,\n",
    "        \"latent_dim\": model_parameters.latent_dim,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787db37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "guide = AutoNormal(model)\n",
    "\n",
    "scheduler = optax.linear_onecycle_schedule(\n",
    "    transition_steps=2_000,\n",
    "    peak_value=0.008,\n",
    "    pct_start=0.2,\n",
    "    pct_final=0.8,\n",
    "    div_factor=3,\n",
    "    final_div_factor=4,\n",
    ")\n",
    "\n",
    "optimizer = optax.chain(\n",
    "    optax.adam(learning_rate=scheduler),\n",
    "    optax.contrib.reduce_on_plateau(\n",
    "        factor=0.1,\n",
    "        patience=10,\n",
    "        accumulation_size=100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "num_steps = 2_000\n",
    "\n",
    "rng_key, rng_subkey = random.split(key=rng_key)\n",
    "\n",
    "svi_result = svi.run(\n",
    "    rng_subkey,\n",
    "    num_steps,\n",
    "    x=x_train,\n",
    "    t=t_train,\n",
    "    y=y_train,\n",
    "    latent_dim=model_parameters.latent_dim,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "ax.plot(svi_result.losses)\n",
    "ax.set_title(\"ELBO loss\", fontsize=18, fontweight=\"bold\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d1984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = svi_result.params\n",
    "\n",
    "train_posterior_predictive = Predictive(\n",
    "    model=model,\n",
    "    guide=guide,\n",
    "    params=params,\n",
    "    num_samples=2_000,\n",
    ")\n",
    "\n",
    "# Generate samples for training data\n",
    "rng_key, rng_subkey = random.split(key=rng_key)\n",
    "train_posterior_predictive_samples = train_posterior_predictive(\n",
    "    rng_subkey, x_train, t_train, y_train, model_parameters.latent_dim\n",
    ")\n",
    "\n",
    "# Convert to ArviZ InferenceData for analysis and visualization\n",
    "train_idata = az.from_dict(\n",
    "    posterior_predictive={\n",
    "        # Add chain dimension for ArviZ compatibility\n",
    "        k: np.expand_dims(a=np.asarray(v), axis=0)\n",
    "        for k, v in train_posterior_predictive_samples.items()\n",
    "    },\n",
    "    coords={\n",
    "        \"feature\": np.arange(x_train.shape[1]),\n",
    "        \"obs_idx\": np.arange(x_train.shape[0]),\n",
    "    },\n",
    "    dims={\n",
    "        \"x_obs\": [\"obs_idx\", \"feature\"],\n",
    "        \"t_obs\": [\"obs_idx\"],\n",
    "        \"y_obs\": [\"obs_idx\"],\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_0_model = do(model, {\"t_obs\": 0})\n",
    "do_1_model = do(model, {\"t_obs\": 1})\n",
    "\n",
    "rng_key, rng_subkey = random.split(rng_key)\n",
    "\n",
    "train_do_0_model_samples = Predictive(\n",
    "    do_0_model, guide=guide, params=params, num_samples=2_000, return_sites=[\"y_logits\"]\n",
    ")(\n",
    "    rng_subkey,\n",
    "    x_train,\n",
    "    t_train,\n",
    "    y_train,\n",
    "    model_parameters.latent_dim,\n",
    ")\n",
    "\n",
    "\n",
    "train_do_1_model_samples = Predictive(\n",
    "    do_1_model, guide=guide, params=params, num_samples=2_000, return_sites=[\"y_logits\"]\n",
    ")(\n",
    "    rng_subkey,\n",
    "    x_train,\n",
    "    t_train,\n",
    "    y_train,\n",
    "    model_parameters.latent_dim,\n",
    ")\n",
    "\n",
    "\n",
    "train_do_0_idata = az.from_dict(\n",
    "    posterior_predictive={\n",
    "        # Add chain dimension for ArviZ compatibility\n",
    "        k: np.expand_dims(a=np.asarray(v), axis=0)\n",
    "        for k, v in train_do_0_model_samples.items()\n",
    "    },\n",
    "    coords={\"obs_idx\": np.arange(x_train.shape[0])},\n",
    "    dims={\"y_obs\": [\"obs_idx\"]},\n",
    ")\n",
    "\n",
    "train_do_1_idata = az.from_dict(\n",
    "    posterior_predictive={\n",
    "        # Add chain dimension for ArviZ compatibility\n",
    "        k: np.expand_dims(a=np.asarray(v), axis=0)\n",
    "        for k, v in train_do_1_model_samples.items()\n",
    "    },\n",
    "    coords={\"obs_idx\": np.arange(x_train.shape[0])},\n",
    "    dims={\"y_probs\": [\"obs_idx\"]},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcde680",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_do_1_idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ba04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_do_1_idata[\"posterior_predictive\"][\"y_logits\"]\n",
    "    - train_do_0_idata[\"posterior_predictive\"][\"y_logits\"]\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d296ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
