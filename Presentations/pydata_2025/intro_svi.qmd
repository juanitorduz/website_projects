---
title: "Scaling Probabilistic Models with Variational Inference"
title-slide-attributes:
  data-background-image: intro_svi_files/static/images/logos/pydata_berlin_logo.png
  data-background-size: cover
  data-background-opacity: "0.15"
subtitle: "PyData Berlin 2025"
author: 
  - name: Dr. Juan Orduz
    url: https://juanitorduz.github.io/

format:
  revealjs:
    slide-number: true
    html-math-method: mathjax 
    css: intro_svi_files/style.css
    logo: intro_svi_files/static/images/logos/pydata_berlin_logo.png 
    transition: none
    chalkboard: 
      buttons: false
    preview-links: auto
    theme:
        - white
    highlight-style: github-dark
---

## Outline

- Motivating Examples:
  - Custom Probabilistic Forecasting Models
  - Hierarchical Cohort Revenue-Retention Models

- Variational Inference in a Nutshell

- **End-to-End Example: Bayesian Neural Network Model**

- References


::: {.callout-tip}
## Code
  
[https://juanitorduz.github.io/intro_svi/](https://juanitorduz.github.io/intro_svi/)
:::


## Toy Example: Two Moons Dataset

Classification problem with non-linear decision boundary.

![](intro_svi_files/static/images/intro_svi_files/intro_svi_6_0.png){fig-align="center" width="1000"}

::: footer
[https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html)
:::

## Model Structure

::: {.callout-tip}
## Model Components
  
- We use a multi-layer perceptron (MLP) to model the non-linear decision boundary parameter $p(x)$.
- We model our data with a Bernoulli likelihood with parameter $p(x)$.

:::


![](intro_svi_files/static/images/intro_svi_files/intro_svi_15_1.svg){fig-align="center" width="1000"}

## Neural Network Component

```{.python code-line-numbers="|1-3|5-10|12-15|17-21"}
from itertools import pairwise
import jax
from flax import nnx

class MLP(nnx.Module):

    def __init__(
        self, din: int, dout: int, hidden_layers: list[int], *, rngs: nnx.Rngs
    ) -> None:
        self.layers = []

        layer_dims = [din, *hidden_layers, dout]

        for in_dim, out_dim in pairwise(layer_dims):
            self.layers.append(nnx.Linear(in_dim, out_dim, rngs=rngs))

    def __call__(self, x: jax.Array) -> jax.Array:
        for layer in self.layers[:-1]:
            x = jax.nn.tanh(layer(x))

        return jax.nn.sigmoid(self.layers[-1](x))
```

## Initialize the Neural Network

```{.python code-line-numbers="|1-3|5-6|8-13"}
import jax.random as random

rng_key, rng_subkey = random.split(rng_key)

hidden_layers = [4, 3]
dout = 1

nnx_module = MLP(
    din=x_train.shape[1],
    dout=dout,
    hidden_layers=hidden_layers,
    rngs=nnx.Rngs(rng_subkey),
)
```

## NumPyro Model

```{.python code-line-numbers="|1-3|5-7|8-13|15-19|21|23-24"}
import numpyro
import numpyro.distributions as dist
from numpyro.contrib.module import random_nnx_module

def model(
    x: Float[Array, "n_obs features"], y: Int[Array, " n_obs"] | None = None
) -> None:
    n_obs: int = x.shape[0]

    def prior(name, shape):
        if "bias" in name:
            return dist.Normal(loc=0, scale=1)
        return dist.SoftLaplace(loc=0, scale=1)

    nn = random_nnx_module(
        "nn",
        nnx_module,
        prior=prior,
    )

    p = numpyro.deterministic("p", nn(x).squeeze(-1))

    with numpyro.plate("data", n_obs):
        numpyro.sample("y", dist.Bernoulli(probs=p), obs=y)
```


## Prior Predictive Checks

![](intro_svi_files/static/images/intro_svi_files/intro_svi_20_0.png){fig-align="center" width="1000"}

## Inference: SVI in NumPyro

## Inference: Early Stopping

![](intro_svi_files/static/images/intro_svi_files/intro_svi_30_0.png){fig-align="center" width="1000"}

## Model Evaluation: Posterior AUC

![](intro_svi_files/static/images/intro_svi_files/intro_svi_39_0.png){fig-align="center" width="1000"}

## Model Evaluation: Posterior ROC

![](intro_svi_files/static/images/intro_svi_files/intro_svi_47_0.png){fig-align="center" width="1000"}

## Posterior Predictive Mean

![](intro_svi_files/static/images/intro_svi_files/intro_svi_49_0.png){fig-align="center" width="1000"}

## Posterior Predictive "Uncertainty"

![](intro_svi_files/static/images/intro_svi_files/intro_svi_51_0.png){fig-align="center" width="1000"}

## Predictions Outside Training Data

![](intro_svi_files/static/images/intro_svi_files/intro_svi_56_0.png){fig-align="center" width="1000"}

## References